<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>zz111y&#39;s stack</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="ㄅㄆㄇㄈㄉㄊㄋㄌ巜ㄎㄏ">
<meta property="og:type" content="website">
<meta property="og:title" content="zz111y&#39;s stack">
<meta property="og:url" content="https://zz111y.github.io/index.html">
<meta property="og:site_name" content="zz111y&#39;s stack">
<meta property="og:description" content="ㄅㄆㄇㄈㄉㄊㄋㄌ巜ㄎㄏ">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="zz111y">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="zz111y's stack" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">zz111y&#39;s stack</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">ㄅㄆㄇㄈㄉㄊㄋㄌ巜ㄎㄏ</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zz111y.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-linux配置git并部署到github" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/linux%E9%85%8D%E7%BD%AEgit%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0github.html" class="article-date">
  <time class="dt-published" datetime="2024-12-22T09:49:07.000Z" itemprop="datePublished">2024-12-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Env-Setting/">Env Setting</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/linux%E9%85%8D%E7%BD%AEgit%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0github.html">linux配置git并部署到github</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="git的安装"><a href="#git的安装" class="headerlink" title="git的安装"></a>git的安装</h1><p>首先更新软件列表：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure><br>然后直接安装：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install git</span><br></pre></td></tr></table></figure></p>
<p><div align="center">
<img src="images/2024/08/4165062626.png" width="80%">
</div></p>
<h1 id="远程连接github"><a href="#远程连接github" class="headerlink" title="远程连接github"></a>远程连接github</h1><p>首先使用以下命令生成ssh公钥<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;email@example.com&quot;</span><br></pre></td></tr></table></figure><br>点击三次enter即可生成。生成后用文本编辑器打开对应的文件(即<strong>id_rsa.pub</strong>)，如下所示：<br><img src="images/2024/08/1616040545.png" alt=""><br><img src="images/2024/08/2075105816.png" alt=""><br>将里面的内容全选复制，打开github，进入个人设置中的SSH and GPG keys中，选择add new SSH key，随便取个title，把刚刚那一堆粘到下面，然后add，就会出现下面这么个东西<br><img src="images/2024/08/1852825467.png" alt=""><br>下面输入<code>ssh -T git@github.com</code>，出现下面这个内容，代表连接成功<br><img src="images/2024/08/2853129452.png" alt=""></p>
<h1 id="git初始化"><a href="#git初始化" class="headerlink" title="git初始化"></a>git初始化</h1><p>新建一个文件夹，运行<code>git init</code>命令初始化该文件夹为git仓库<br><img src="images/2024/08/1455528370.png" alt=""><br>然后用以下命令设置username和email：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;Your name&quot;</span><br><span class="line">git config --global user.email &quot;Your email&quot;</span><br></pre></td></tr></table></figure><br>配置好后，使用<code>git config --lsit</code>可以查看配置信息，如下：<br><img src="images/2024/08/1953203131.png" alt=""></p>
<h1 id="连接远程仓库"><a href="#连接远程仓库" class="headerlink" title="连接远程仓库"></a>连接远程仓库</h1><p>在github的repository主页可以看到以下内容<br><img src="images/2024/08/3556235606.png" alt=""><br>复制SSH的内容，执行以下语句：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin git@github.com:xxx/xxx.git</span><br></pre></td></tr></table></figure><br>其中origin是你本机为这个仓库起的别名，后面是复制粘贴来的，即可连接到远程仓库。连接好后，使用<code>git remote -v</code>即可查看。</p>
<h1 id="上传到远程仓库"><a href="#上传到远程仓库" class="headerlink" title="上传到远程仓库"></a>上传到远程仓库</h1><p>首先我们写一个文件，然后用add命令将其放到staging area，然后用commit命令将其送到local repository：<br><img src="images/2024/08/2940412778.png" alt=""><br>下一步就可以用push命令将其推送到远程：<br><img src="images/2024/08/1711395986.png" alt=""><br>这时候远程仓库就有本次推送了。</p>
<hr>
<h1 id="一些基本操作"><a href="#一些基本操作" class="headerlink" title="一些基本操作"></a>一些基本操作</h1><ul>
<li><strong>常用查找项目前后缀</strong><ul>
<li>awesome xxx：百科全书</li>
<li>xxx sample：找示例</li>
<li>xxx starter/boilerplate：空项目框架</li>
<li>xxx tutorial：教程</li>
</ul>
</li>
<li><strong>“借鉴”他人的项目</strong><br>在terminal使用<code>git clone URL</code>即可拷贝指定URL的项目到所在文件夹</li>
<li><strong>git clone和下载zip解压有什么不同</strong><br>git clone下来的是一个<strong>仓库</strong>，会有一个.git文件，可以执行git相关操作；而download zip得到的没有，需要<code>git init</code>才能让其成为仓库</li>
<li><strong>提交文件</strong><br>git有三个区域：working dir（当前实际操作的地方）、stage（临时保存改动）、HEAD（指向最后一次提交）<br><img src="images/2024/08/336506818.png" alt=""><ul>
<li><strong>提出更改</strong>（放到stage）：git add <filename>，使用git add -A可以提交所有更改</li>
<li><strong>提交更改</strong>（提交到HEAD）：git commit -m “commit-information”</li>
</ul>
</li>
<li><strong>查看历史提交</strong><br>使用<code>git log --stat</code>可以查看历史提交</li>
<li><strong>替换本地改动</strong><br>使用<code>git checkout &lt;filename&gt;</code>可以将HEAD中的内容替换掉工作目录中的文件，不会影响stage和新建文件。<br>如果已经commit，可以丢弃所有改动，在远程仓库获取最新版本并使本地主分支指向它：<br><code>git fetch origin</code>、<code>git reset --hard origin/master</code>；或者可以使用<code>git reset HEAD^x</code>回到上x个commit；或者可以直接到history版本中将改动部分复制粘贴回来。</li>
<li><strong>分支</strong><br>master一般放已经完善的代码，如果某个项目需要长时间的开发，建议使用分支功能将其放到另一个分支上，并在完善后将其合并到master上。不同分支互不影响。<ul>
<li>查看所有分支：<code>git branch</code></li>
<li>在当前分支新建分支：<code>git checkout -b &lt;branchname&gt;</code></li>
<li>切换分支：<code>git checkout &lt;mastername&gt;</code></li>
<li>删除分支：<code>git checkout -d &lt;branchname&gt;</code></li>
<li>将指定分支合并到当前分支：<code>git merge &lt;branchname&gt;</code></li>
<li>遇到无法处理的冲突，停止合并：<code>git merge abort</code></li>
</ul>
</li>
<li><strong>交互远程仓库</strong><ul>
<li>推送HEAD中更改：<code>git push origin branch</code>，其中branch是分支名</li>
<li>拉取远程仓库：<code>git pull origin branch</code></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/linux%E9%85%8D%E7%BD%AEgit%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0github.html" data-id="cm4zg7wz90002we3khjy0aoyd" data-title="linux配置git并部署到github" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-ubuntu下用qemu模拟freedos编写16位汇编语言" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/ubuntu%E4%B8%8B%E7%94%A8qemu%E6%A8%A1%E6%8B%9Ffreedos%E7%BC%96%E5%86%9916%E4%BD%8D%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80.html" class="article-date">
  <time class="dt-published" datetime="2024-10-13T10:21:00.000Z" itemprop="datePublished">2024-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Env-Setting/">Env Setting</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/ubuntu%E4%B8%8B%E7%94%A8qemu%E6%A8%A1%E6%8B%9Ffreedos%E7%BC%96%E5%86%9916%E4%BD%8D%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80.html">ubuntu下用qemu模拟freedos编写16位汇编语言</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>最近在做微机原理实验，需要用到dos系统+8086写汇编，同时os课程中也对模拟操作系统有一定的需求，因此选择了qemu作为操作平台。</p>
<p>根据我的理解，qemu就是一个虚拟机管理程序，可以用它来在PC上模拟各种操作系统、架构（其实就是给你一个空壳子cpu，包括x86的、arm的、risc-v的等等）</p>
<h1 id="一个例子——qemu模拟ubuntu"><a href="#一个例子——qemu模拟ubuntu" class="headerlink" title="一个例子——qemu模拟ubuntu"></a>一个例子——qemu模拟ubuntu</h1><p>先拿用qemu模拟ubuntu来举例，熟悉一下用qemu的流程，加深一下对qemu的理解<br>首先安装qemu<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install qemu qemu-kvm</span><br></pre></td></tr></table></figure><br>这里的qemu-kvm具体是什么并没有具体了解，只是知道他可以让你拥有<strong>更好的体验</strong>。<br>然后创建一个虚拟硬盘文件（默认在当前路径）：<br><code>qemu-img create -f qcow2 ubuntu-vm.img 20G</code><br>qemu-img用于操作虚拟硬盘镜像文件</p>
<ul>
<li><code>-f qcow2</code>指定了镜像的格式，qcow2就是一种格式</li>
</ul>
<p>剩下两个参数就是名字和大小，不做过多解释。但有一点要注意的是，虽然指定了20G，但它一开始不会用那么多，qcow2只会在写入数据时动态分配空间。<br><strong>可以使用<code>qemu-img info xxx.img</code>查看虚拟硬盘信息</strong>。</p>
<p>假设我们已经有了一个ubuntu.iso文件，那么就可以用qemu启动这个镜像了：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 -boot d -cdrom ubuntu.ios -m 2048 -hda ubuntu-vm.img -cpu host -smp 2</span><br></pre></td></tr></table></figure><br>解释一下这些参数：</p>
<ul>
<li><code>qemu-system-x86_64</code>：指定使用x86-64架构的qemu</li>
<li><code>-boot d</code>：指定从光盘设备cdrom启动，通常用于从iso镜像启动操作系统</li>
<li><code>-cdrom ubuntu.iso</code>：指定要加载的iso文件作为cdrom设备，这里用的是我们下载的ubuntu.iso</li>
<li><code>-m 2048</code>：为其分配2048MB内存</li>
<li><code>-hda ubuntu-vm.img</code>：指定虚拟硬盘文件</li>
<li><code>-cpu host</code>：让qemu使用PC的CPU功能，提高性能</li>
<li><code>-smp 2</code>：为虚拟机分配两个CPU核心</li>
</ul>
<p>然后就会打开qemu界面开始安装了。这里省略安装过程，假设已经安装完成，那么下次启动的时候就可以直接：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x8^_64 -m 2048 -hda ubuntu-vm.img -cpu host -smp 2</span><br></pre></td></tr></table></figure><br>这样qemu就会直接从对应的虚拟硬盘启动操作系统了。<br>[scode type=”blue”]</p>
<ul>
<li><strong>iso文件</strong>：光盘映像（CD image），具体应用有：安装操作系统，软件分发、系统备份恢复、创建可启动的USB</li>
<li><strong>img文件</strong>：磁盘影像，具体应用有：硬盘备份和恢复、嵌入式开发、虚拟机映像、usb驱动器映像</li>
</ul>
<p>[/scode]<br>[scode type=”share”]<br>对模拟ubuntu系统（其实就是装系统）的进一步理解：<br>在命令<code>qemu-system-x86_64 -boot d -cdrom ubuntu.iso -m 2048 -hda ubuntu-vm.img -cpu host -smp 2</code>中，我们可以看到，同时指定了iso文件和img文件。iso文件的作用是<strong>指定了要从中引导的光盘映像</strong>，<code>-boot d</code>表示虚拟机会首先尝试从光盘设备启动，那么qemu就会从ubuntu.iso中加载操作系统的安装程序，允许用户在虚拟机中安装ubuntu；而img文件指定了虚拟机的硬盘镜像文件，我们在安装ubuntu时，<strong>系统会将文件、配置和用户数据写入ubuntu-vm.img</strong>，那么安装好下次启动时，就可以直接从ubuntu-vm.img启动了，而不再需要从iso文件启动。<br>[/scode]</p>
<h1 id="模拟dos"><a href="#模拟dos" class="headerlink" title="模拟dos"></a>模拟dos</h1><p>我们从<a target="_blank" rel="noopener" href="http://freedos.org">freedos官网</a>下载好镜像文件，我下载到的是FD13-LiveCD.zip文件，解压后得到了一个FD13BOOT.img文件和FD13LIVE.iso文件，总之最后能得到iso文件就行了<br>然后我们创建一个虚拟硬盘<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-img create -f qcow2 freedos.img 500M</span><br></pre></td></tr></table></figure><br>然后直接用iso文件启动安装即可：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-i386 -hda freedos.img -cdrom FD13Live.iso -boot d</span><br></pre></td></tr></table></figure><br>[scode type=”share”]i386是用于模拟intel 80386(i386)及其兼容处理器的虚拟机，i386是intel第三代x86处理器架构，也被称为intel 386，他是第一款支持32位运算的处理架构。同时，他也向后兼容16位的dos系统。[/scode]<br>这里-m默认256MB或512MB，-cpu默认选择了兼容的，-smp默认使用1个。freedos是一个轻量级的操作系统，这些对freedos足够了。安装时，选择install to harddisk。</p>
<p>经历漫长的安装后，得到如下界面，输入ver可查看freedos版本信息，代表安装成功：<br><img src="images/2024/10/3951787082.png" alt="2024-10-12T17:06:25.png"><br>然后我们在终端ctrl+c退出qemu，再次开启时，只要使用<code>qemu-system-x86_64 -hda freedos.img</code>即可无需iso启动。</p>
<h1 id="安装nasm"><a href="#安装nasm" class="headerlink" title="安装nasm"></a>安装nasm</h1><p>编译汇编我选择了<a target="_blank" rel="noopener" href="https://www.nasm.us/">nasm</a>，下载好程序zip后，解压到本地。现在的问题就是，nasm是下载到本地的，而不是下载到虚拟机上的，虚拟dos上固然无法直接访问PC上的文件，并且为虚拟dos联网也麻烦的很。因此我们这里选择<strong>设置一块额外的虚拟硬盘放nasm，然后挂载到dos</strong>。</p>
<p>首先建一个img：<code>qemu-img create -f qcow2 nasm.img 30M</code><br>然后<code>qemu-system-i386 -hda freedos.img -hdb nasm.img -boot c</code>，即可启动freedos，并将nasm.img挂载为第二块硬盘。<br>然后我们需要对其进行格式化，使得dos能识别他。首先使用fdisk命令进入硬盘管理，选择选项5：change current fixed disk drive，这里应该能看到刚刚挂载的第二块硬盘，只是他还没有被格式化。然后选择它，<br>选择选项1：create dos partition or logical dos drive，选择选项1：create primary dos partition，创建好后选择选项2：set active partition激活他，然后重启dos。<br>重启后，进入分区D：<code>D:</code>，使用<code>format D:</code>可对D:进行格式化，输入一个volume label（随意）即可。<br>最后输入<code>dir</code>，如果显示no files证明挂载成功。</p>
<p>现在我们要处理的下一个问题是，将nasm文件拷贝到我们的虚拟硬盘里。这里使用nbd（network block device）的方法，这种方法可以将远程服务器上的块设备（硬盘、硬盘镜像等）暴露为本地设备，并像本地硬盘一样读写。<br>回到ubuntu终端，依次执行以下命令：</p>
<ol>
<li><code>sudo modprobe nbd</code>：加载内核模块nbd，使得linux系统可以支持nbd；</li>
<li><code>sudo qemu-nbd --connect=/dev/nbd0 nasm.img</code>：使用qemu-nbd将虚拟硬盘镜像暴露为本地块设备，并把nasm.img视作/dev/nbd0</li>
<li><code>sudo mount /dev/nbd0 /mnt</code>：使用mount命令将/dev/nbd0挂载到/mnt上，挂载后虚拟硬盘镜像的内容会显示在/mnt目录下，用户可以读写该镜像内容（使用<code>sudo fdisk -l /dev/nbd0</code>可查看其信息，如果是fat16文件系统，则需要使用：<code>sudo mount /dev/nbd0p0 /mnt</code>）</li>
<li><code>sudo cp /path_to_nasm/* /mnt</code>：将nasm里的东西复制到已经挂载的虚拟硬盘镜像内（即/mnt）</li>
<li><code>sudo umount /mnt</code>：将虚拟硬盘镜像从/mnt卸载</li>
<li><code>sudo qemu-nbd --disconnect /dev/nbd0</code>：断开nasm.img与/dev/nbd0的连接，取消对nasm.img的映射</li>
</ol>
<p>再次用<code>qemu-system-i386 -hda freedos.img -hdb nasm.img -boot c</code>启动dos后，进入D盘，即可看到nasm的相关文件已经存在，此时输入<code>nasm</code>，显示如下内容，表示安装成功：<br><img src="images/2024/10/39489604.png" alt=""></p>
<p>我们还可以做进一步的升级。此时nasm只有在其所在文件夹才能运行，我们要把它配为环境变量，这样，在任何地方都能使用nasm命令了。<br>用<code>echo %path%</code>可以查看系统默认环境变量目录，我这里是c:\freedos\bin，现在我们只要把nasm.exe复制到这里面即可：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">copy your_path\nasm.exe c:\freedos\bin\</span><br></pre></td></tr></table></figure><br>回到C盘，运行<code>nasm -V</code>可查看版本，代表配置成功。</p>
<h1 id="编写汇编程序代码并测试运行"><a href="#编写汇编程序代码并测试运行" class="headerlink" title="编写汇编程序代码并测试运行"></a>编写汇编程序代码并测试运行</h1><p>使用<code>edit hello.asm</code>创建第一个汇编程序，然后编辑以下内容：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">section .data</span><br><span class="line">    msg db &#x27;Hello, World!&#x27;, &#x27;$&#x27;  ; 字符串以 $ 结束</span><br><span class="line"></span><br><span class="line">section .text</span><br><span class="line">    org 0x100  ; 程序开始地址为0x100</span><br><span class="line"></span><br><span class="line">start:</span><br><span class="line">    ; 输出字符串</span><br><span class="line">    mov dx, msg   ; 将消息地址加载到DX寄存器</span><br><span class="line">    mov ah, 9     ; DOS功能调用，功能号9（显示字符串）</span><br><span class="line">    int 0x21      ; 通过中断调用DOS服务</span><br><span class="line"></span><br><span class="line">    ; 正常退出程序</span><br><span class="line">    mov ah, 0x4c  ; DOS功能调用，功能号4Ch（终止程序）</span><br><span class="line">    int 0x21      ; 通过中断返回到DOS</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>保存退出后，使用<code>nsam -f bin hello.asm -o hello.com</code>编译，生成一个hello.com的可执行文件，然后直接<code>hello.com</code>，就可以在屏幕上打印出对应内容了。</p>
<p>参数解释：<br><code>-f bin</code>：指定输出文件格式为binary，<code>-f bin</code>表示生成一个不包含头部信息的纯二进制文件，这个文件可以直接在dos或其他兼容的系统上执行。<br>[scode type=”share”]COM文件是简单的二进制文件，不包含任何文件头或元数据。这使得加载和执行过程非常简单。DOS 在加载 COM 文件时只需将其内容直接放入内存并跳转到指定地址（通常是 0x100）。[/scode]</p>
<h1 id="后记——在dos中debug汇编代码"><a href="#后记——在dos中debug汇编代码" class="headerlink" title="后记——在dos中debug汇编代码"></a>后记——在dos中debug汇编代码</h1><p>以上面的程序为例，执行<code>debug hello.com</code>，即可进入debug<br>[scode type=”share”]dos内置debug，可以用来调试.com文件或.exe文件[/scode]<br>常见debug命令：</p>
<ul>
<li>D(Dump)：显示内存内容，例如<code>d 0100</code>会从0100开始显示内存</li>
<li>E(Enter)：修改内存内容，例如<code>e 0100</code>可以修改地址0100的内容</li>
<li>R(Register)：显示和修改寄存器，例如<code>r</code>可以显示所有寄存器内容，<code>r ax</code>可以修改ax的值</li>
<li>T(Trace)：单步执行</li>
<li>G(Go)：运行程序直到遇到<code>int 20h</code>或<code>int 21h</code></li>
<li>Q(Quit)：退出debug</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/ubuntu%E4%B8%8B%E7%94%A8qemu%E6%A8%A1%E6%8B%9Ffreedos%E7%BC%96%E5%86%9916%E4%BD%8D%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80.html" data-id="cm4zg7wzb0006we3k4vqa2zgj" data-title="ubuntu下用qemu模拟freedos编写16位汇编语言" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-week12-extra-Q-learning" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/week12-extra-Q-learning.html" class="article-date">
  <time class="dt-published" datetime="2024-10-05T15:02:00.000Z" itemprop="datePublished">2024-10-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NTU-ML2022/">NTU-ML2022</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/week12-extra-Q-learning.html">[week12 extra] Q-learning</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在RL中，学习了critic的方法。本篇文章将介绍另一种设计critic的方法：State-action value function。</p>
<h1 id="State-action-value-function-Q-pi-s-a"><a href="#State-action-value-function-Q-pi-s-a" class="headerlink" title="State-action value function $Q^\pi(s,a)$"></a>State-action value function $Q^\pi(s,a)$</h1><p>$Q^\pi(s,a)$的定义是<strong>给定一个actor $\pi$，在state $s$下采取action $a$后期望得到的reward</strong>。<br>通俗来讲，在state $s$下，actor不一定采取action $a$，但我们强制采取action $a$，后面让actor自己玩下去会得到的cumulated reward。<br>$Q^\pi$有两种表示方法，其中第二种只适用于action是离散的情况：<br><img src="images/2024/10/3535350820.png" alt="$Q^\pi$"></p>
<p>训练出这样一个Q-function，即可做RL，叫做Q-learning。整体框架如下：<br><img src="images/2024/10/2774954914.png" alt="Q-learning"></p>
<ol>
<li>初始化一个policy $\pi$（可随机）</li>
<li>用这个policy去learn一个Q-function（用TD or MC）</li>
<li><strong>只要learn到这个Q-function，那么一定能找到一个更好的policy $\pi^\prime$</strong></li>
</ol>
<p>如何定义“更好”：对于所有的state $s$，$V^{\pi^\prime}(s)\geq V^\pi(s)$<br>有了Q后，找$\pi^\prime$的方法：$\pi^\prime(s)=\mathop{\arg\max}\limits_aQ^\pi(s,a)$<br>上式的意思为，假设我们<strong>已经learn到了$\pi$的Q-function</strong>，现在<strong>给定某一个state $s$</strong>，我们把<strong>所有可能的action一一代入Q-function</strong>，看看<strong>哪个a可以让Q-function的value最大</strong>，那么这个action就是<strong>$\pi^\prime$会在$s$下采取的action</strong>。<br>实际上没有一个network来确定$\pi^\prime$，他是根据Q-function推出来的。但是这里存在的问题是action可能是continuous的，这个后面解决。<br>[scode type=”share”]对$\pi^\prime$一定比$\pi$好的证明：<br>已知$\pi^\prime(s)=\mathop{\arg\max}\limits_aQ^\pi(s,a)$，要证明对于所有的state $s$，$V^{\pi^\prime}(s)\geq V^\pi(s)$<br>证明：<br>$V^\pi(s)=Q^\pi(s,\pi(s))\leq\mathop{\max}\limits_aQ^\pi(s,a)=Q^\pi(s,\pi^\prime(s))$<br>即$V^\pi(s)\leq Q^\pi(s,\pi^\prime(s))$<br>而</p>
<script type="math/tex; mode=display">
\begin{align*}
  V^\pi(s) &\leq Q^\pi(s,\pi^\prime(s)) \\
    &= E[r_t+V^\pi(s_{t+1})|s_t=s,a_t=\pi^\prime(s_t)] \\
    &\leq E[r_t+Q^\pi(s_{t+1},\pi^\prime(s_{t+1})|s_t=s,a_t=\pi^\prime(s_t)] \\
    &= E[r_{t}+r_{t+1}+V^\pi(s_{t+2})|...] \\
    &\leq E[r_{t}+r_{t+1}+Q^\pi(s_{t+2},\pi^\prime(s_{t+2})|...]...\leq V^{\pi^\prime}(s)
\end{align*}</script><p>[/scode]</p>
<h1 id="Tips-of-Q-learning"><a href="#Tips-of-Q-learning" class="headerlink" title="Tips of Q-learning"></a>Tips of Q-learning</h1><h2 id="Target-Network"><a href="#Target-Network" class="headerlink" title="Target Network"></a>Target Network</h2><p>假如我们使用TD来定义critic，那么有：$Q^\pi(s_t,a_t)=r_t+Q^\pi(s_{t+1},\pi(s_{t+1}))$<br>在learn的时候会发现这样的function并不好learn。假设这是一个regression的问题，那么你会发现output $Q^\pi(s_t,a_t)$和target $r_t+Q^\pi(s_{t+1},\pi(s_{t+1}))$都是会变化的。相当于要fit的target一直在变化。那么我们在实作的时候会固定产生target的$Q^\pi$的参数，这个$Q^\pi$叫做target network，那么此时得到的target就是固定的了。实作时，会update多次后统一$Q^\pi$。<br><img src="images/2024/10/830663718.png" alt="target network"></p>
<h2 id="Exploration"><a href="#Exploration" class="headerlink" title="Exploration"></a>Exploration</h2><p>由于$a=\mathop{\arg\max}\limits_aQ(s,a)$，policy只会采取固定的action。<br>假设要估测在state $s$采取某个action得到的Q-value，那么一定要在那个state采取过那个action（如果Q-function是network的话，问题不会非常严重）。如果没采取过那个action，那么估测出来的Q-value就会都是一个初始值。这样就只会一直sample到之前采取过的某个action。<br>因此就需要Exploration，让actor探索更多的可能。<br>解决方法：<br><img src="images/2024/10/878581452.png" alt=""></p>
<h2 id="Replay-Buffer"><a href="#Replay-Buffer" class="headerlink" title="Replay Buffer"></a>Replay Buffer</h2><p>把每个policy和环境互动搜集到的资料放到replay buffer里面，装满后丢掉旧的资料。因此replay buffer里面装的是很多不同的policy搜集到的资料。训练的时候，在replay buffer里随机sample一些data去训练。这样做好似变成了off-policy的，这样做的好处：</p>
<ul>
<li>大大减小和环境互动搜集资料的时间</li>
<li>data更加diverse</li>
</ul>
<p>[scode type=”yellow”]我们需要的是$\pi$的experience，但如果用replay buffer的话，不就混杂了一些其他的experience吗？<br>在理论上没有问题，留作思考[/scode]</p>
<h2 id="Typical-Q-learning-Algorithm"><a href="#Typical-Q-learning-Algorithm" class="headerlink" title="Typical Q-learning Algorithm"></a>Typical Q-learning Algorithm</h2><ul>
<li>初始化Q-function $Q$以及target Q-function $\hat Q=Q$</li>
<li>对于每个episode<ul>
<li>对于每个step $t$<ul>
<li>给定一个state $s_t$，依据$Q$采取一个action $a_t$（exploration）</li>
<li>获得reward $r_t$，到达新的state $s_{t+1}$</li>
<li>将$(s_t,a_t,r_t,s_{t+1})$放入replay buffer</li>
<li>从replayb buffer中sample一批$(s_i,a_i,r_i,s_{i+1})$</li>
<li>计算target $y=r_i+\mathop{\max}\limits_a\hat Q(s_{i+1},a)$</li>
<li>更新$Q$使得$Q(s_i,a_i)$和$y$越近越好（regression）</li>
<li>每C步令$\hat Q=Q$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h2><p>Q-value经常会被高估：<br><img src="images/2024/10/3132934395.png" alt=""><br>实际的值往往小于Q-value，用Double DQN估测的值会和实际的值很接近。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/week12-extra-Q-learning.html" data-id="cm4zg7wzb0009we3ked2z1jem" data-title="[week12 extra] Q-learning" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-ubuntu环境下多版本cuda的安装与切换" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/ubuntu%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%A4%9A%E7%89%88%E6%9C%ACcuda%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%87%E6%8D%A2.html" class="article-date">
  <time class="dt-published" datetime="2024-10-04T15:05:00.000Z" itemprop="datePublished">2024-10-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Env-Setting/">Env Setting</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/ubuntu%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%A4%9A%E7%89%88%E6%9C%ACcuda%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%87%E6%8D%A2.html">ubuntu环境下多版本cuda的安装与切换</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>因为最近一个项目需要cuda11，而电脑上装的是cuda12，所以需要回退一下cuda版本。偶然间找到了一个可以多版本cuda切换的方法，感觉非常有用，遂配置一下。</p>
<h2 id="卸载旧的驱动以及cuda（可选）"><a href="#卸载旧的驱动以及cuda（可选）" class="headerlink" title="卸载旧的驱动以及cuda（可选）"></a>卸载旧的驱动以及cuda（可选）</h2><p>卸载cuda执行<code>sudo /usr/local/cuda-12.2/bin/cuda-uninstaller</code>，其中版本号对应自己文件夹下的即可。删除后将cuda-12.2文件夹也<code>rm -rf</code>即可。<br>卸载驱动执行<code>sudo apt --purge remove nvidia*</code>，—purge参数可以在删除包的同时删除配置文件。</p>
<h2 id="安装驱动"><a href="#安装驱动" class="headerlink" title="安装驱动"></a>安装驱动</h2><p>首先安装必要的工具：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install g++</span><br><span class="line">sudo apt install gcc</span><br><span class="line">sudo apt install make</span><br></pre></td></tr></table></figure><br>然后看一下自己有没有装nv显卡驱动，执行<code>nvidia-smi</code>，出现以下界面则表示已安装：<br><img src="images/2024/09/4289696257.png" alt=""><br>如果没有，则需要先安装一下。首先执行<code>ubuntu-drivers devices</code>可以查看电脑适合的显卡驱动版本：<br><img src="images/2024/09/1640923122.png" alt=""><br>可以看到我的电脑推荐安装550版本，那么就<code>sudo apt install nvidia-driver-550</code>即可。安装后重启电脑，使用<code>nvidia-smi</code>命令，出现上述窗口代表安装成功。</p>
<h2 id="安装cuda"><a href="#安装cuda" class="headerlink" title="安装cuda"></a>安装cuda</h2><p>执行<code>nvidia-smi</code>，右上角的cuda version显示了当前电脑gpu支持的最高cuda版本（安装小于等于这个版本的cuda均可）。然后到<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit Archive</a>下载对应版本即可，加载可能非常慢，耐心等待（有时候能不能打开还是很玄学的）。例如我选择了12.4版本，那么如下勾选：<br><img src="images/2024/09/3160448326.png" alt=""><br>随后会获得两个命令，将其cv到terminal执行即可。然后就进行漫长的下载..wget下载好后执行.run文件即可。<br>运行后，首先选择continue，然后输入accept，然后会出现如下界面：<br><img src="images/2024/09/248249107.png" alt=""><br>由于我们已经安装了驱动，因此取消勾选driver即可，然后选择install。<br>如果我们的已经安装了一个另一个版本的cuda，那么会出现下面的界面:<br><img src="images/2024/10/802254790.png" alt=""><br>Yes即把当前版本切换为新安装的，No即暂时不切换。<br>等待一段漫长的时间后，应该会得到这样一个界面：<br><img src="images/2024/09/4118339662.png" alt=""><br>现在需要配置一下环境。先<code>sudo gedit ~/.bashrc</code>（gedit(GNOME text editor)，用于编辑文本信息），然后将下面三条配置添加到最下面：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export PATH=$PATH:/usr/local/cuda/bin  </span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64  </span><br><span class="line">export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda/lib64</span><br></pre></td></tr></table></figure><br>然后保存，退出即可。然后执行<code>source ~/.bashrc</code>使环境生效即可。这时候执行<code>nvcc -V</code>，即可显示当前cuda版本：<br><img src="images/2024/09/3016187464.png" alt=""></p>
<h2 id="安装cudnn"><a href="#安装cudnn" class="headerlink" title="安装cudnn"></a>安装cudnn</h2><p>首先到<a target="_blank" rel="noopener" href="https://developer.nvidia.com/rdp/cudnn-archive">cudnn官网</a>下载对应版本的cudnn，下载下来应该是一个tgz文件，然后解压即可。然后更改一下/usr/local/cuda-xx.x里include目录的权限<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/cuda-xx.x</span><br><span class="line">sudo chmod 666 include</span><br></pre></td></tr></table></figure><br>然后进入到解压后的cudnn目录的上级目录，执行官网提供的以下操作，将一些必要的东西放到cuda-xx.x文件夹里。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo cp cudnn-*-archive/include/cudnn*.h /usr/local/cuda-xx.x/include</span><br><span class="line">sudo cp -P cudnn-*-archive/lib/libcudnn* /usr/local/cuda-xx.x/lib64</span><br><span class="line">sudo chmod a+r /usr/local/cuda-xx.x/include/cudnn*.h /usr/local/cuda-xx.x/lib64/libcudnn*</span><br></pre></td></tr></table></figure></p>
<h2 id="多版本cuda切换"><a href="#多版本cuda切换" class="headerlink" title="多版本cuda切换"></a>多版本cuda切换</h2><p>/usr/local下应该会有一个cuda文件夹，这个文件夹软链接向当前使用的cuda版本（类比于快捷方式），因此切换版本只需要切换其软链接指向即可。<br>使用<code>stat /usr/local/cuda</code>命令可查看当前使用的版本号：<br><img src="images/2024/10/947729296.png" alt=""><br>要切换版本，首先删除当前cuda软链接：<br><code>sudo rm -rf /usr/local/cuda</code><br>然后新建软链接指向想要的版本即可：<br><code>sudo ln -s /usr/local/cuda-xx.x /usr/local/cuda</code></p>
<p>完成这些操作后，输入以下命令，即可查看cudnn版本号<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2</span><br></pre></td></tr></table></figure><br><img src="images/2024/09/3863028836.png" alt=""><br>同样也可以使用<code>nvcc -V</code>查看当前cuda版本。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/ubuntu%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%A4%9A%E7%89%88%E6%9C%ACcuda%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%87%E6%8D%A2.html" data-id="cm4zg7wz90003we3kfq7y1gph" data-title="ubuntu环境下多版本cuda的安装与切换" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-week12-Reinforcement-Learning" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/week12-Reinforcement-Learning.html" class="article-date">
  <time class="dt-published" datetime="2024-10-03T16:43:00.000Z" itemprop="datePublished">2024-10-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NTU-ML2022/">NTU-ML2022</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/week12-Reinforcement-Learning.html">[week12]Reinforcement Learning</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="What-is-RL"><a href="#What-is-RL" class="headerlink" title="What is RL"></a>What is RL</h1><p>RL也是ML的一种，因此其本质也是找一个function。<br>在RL中，有一个actor和一个environment，environment给actor一个observation，actor根据observation产生一个action，此action会影响environment，同时environment会给actor一个reward来判断此action的好坏。而我们要找的function其实就是actor，目标是maximize reward。<br><img src="images/2024/10/232325698.png" alt="RL"></p>
<p>由于我们说RL也是ML的一种，那么实现的流程自然有三步：</p>
<ol>
<li><strong>Function with Unknown</strong><br>Actor就是一个Policy Network，它的input是observation，output是action。<br><img src="images/2024/10/2686095016.png" alt="Policy Network"></li>
<li><strong>Define “Loss”</strong><br>假如在玩space invader，那么经过很多个turns后游戏结束，从游戏开始到结束的整个过程叫做一个episode，这中间会得到很多reward，Total reward(R,or return)就是reward的总和：<script type="math/tex; mode=display">R=\sum\limits_{t=1}^Tr_t</script>我们的目标就是maximize这个R，如果给他加个负号，那就可以是loss了。</li>
<li><strong>Optimization</strong><br>整个流程是一个observation产生一个action，此action影响env产生另一个observation…以此类推，整个流程可以看做一个observation和action的sequence，记作$\tau$。而我们要optimize的就是每一组observation和action对应得到的reward之和。<br><img src="images/2024/10/1212833890.png" alt=""><br>实际上要面临的问题有很多，首先actor是<strong>sample出来的</strong>，说明这个大network的某个layer是随机的；另外，env和reward根本就<strong>不是network</strong>，他们都更像一个blackbox；更糟糕的是，reward和env都是带有<strong>随机性</strong>的。<br>因此，<strong>RL真正的crux在于如何Optimization</strong>。</li>
</ol>
<h1 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h1><h2 id="How-to-control-your-actor"><a href="#How-to-control-your-actor" class="headerlink" title="How to control your actor"></a>How to control your actor</h2><p>当actor遇到某个observation $s$的时候，你想要让actor采取某个特定的action $\hat a$，或者遇到$s\prime$的时候，你想要让actor不采取某个action $\hat a\prime$（可以采取任何其他action），可以采取以下策略：<br><img src="images/2024/10/3454436464.png" alt="control your actor"><br>其中$e$是cross-entropy。由此我们就可以得到一种Loss的定义方式：<br><img src="images/2024/10/2951333223.png" alt=""><br>当然可以更进一步的修改，原本的是<strong>要执行-不要执行</strong>的binary classify的问题，我们可以定义更加细化的expect：<br><img src="images/2024/10/962072055.png" alt=""><br>这样做的难点在于如何确定$A$的值以及如何得到Training Data。</p>
<h2 id="Loss-Version0"><a href="#Loss-Version0" class="headerlink" title="Loss Version0"></a>Loss Version0</h2><p>随机初始化一个actor，让他去env中实践一下，得到一系列的observation、action和reward，直接用reward当做A的值：<br><img src="images/2024/10/3680080204.png" alt="version0"><br>但是这样做，完全没有考虑全局，而只是考虑了当前这一步的reward。因此这样做的效果并不好。并且，<strong>牺牲当下利益获取长远利益</strong>也是很重要的，而这种做法完全不会考虑这种情况。</p>
<h2 id="Version1"><a href="#Version1" class="headerlink" title="Version1"></a>Version1</h2><p>改进一下，加上全局的考虑，可以累加当前action后所有的reward作为评估标准，我们将cumulated reward记作G：<br><img src="images/2024/10/2585770038.png" alt="version1"><br>但这样，越靠前的action就会积累到更大的reward，这明显不太合理。</p>
<h2 id="Version2"><a href="#Version2" class="headerlink" title="Version2"></a>Version2</h2><p>我们给cumulated reward加上一个discount factor：<br><img src="images/2024/10/901892879.png" alt="version2"></p>
<h2 id="Version3"><a href="#Version3" class="headerlink" title="Version3"></a>Version3</h2><p>好坏是相对的，因此我们要对G进行normalization：<br><img src="images/2024/10/3283872722.png" alt="version3"></p>
<h2 id="policy-gradient"><a href="#policy-gradient" class="headerlink" title="policy gradient"></a>policy gradient</h2><p>有了Optimization的目标后，那么就能做Gradient Descent了：<br><img src="images/2024/10/2615272301.png" alt="policy gradient"><br>我们发现，收集training data是在for循环里进行的，因此每次迭都需要data collection，这是<strong>非常花时间</strong>的。<br>[scode type=”yellow”]同一批action data，对于不同的actor parameters效果是不同的，因此需要不停的搜集新的data。[/scode]<br>[scode type=”green”]搜集资料的时候，要有一定的exploration，即actor会采取更加随机的action，这样做能让actor尝试更多的可能。[/scode]</p>
<h2 id="On-policy-v-s-Off-policy"><a href="#On-policy-v-s-Off-policy" class="headerlink" title="On-policy v.s. Off-policy"></a>On-policy v.s. Off-policy</h2><p>上面讲到的<strong>要训练的actor</strong>与<strong>和env互动的actor</strong>是同一个actor，叫做<strong>on-policy</strong>，如果二者是不同的actor，那么叫做<strong>off-policy</strong>。off-policy的好处是：<strong>可以减少收集资料的次数</strong>。<br>一个常用的off-policy的方法：<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=OAKAZhFmYoI">PPO</a></p>
<h1 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h1><p>critic的含义即<strong>给定一个observing s，某个actor $\theta$的好坏</strong>。<br>以value function$V^\theta(s)$举例，给定一个actor和一个obeservation，它能“未卜先知”预测cumulated reward。<br>实际上，$V^\theta(s)$是一个network，我们需要去训练他。</p>
<h2 id="How-to-estimate-V-theta-s"><a href="#How-to-estimate-V-theta-s" class="headerlink" title="How to estimate $V^\theta(s)$"></a>How to estimate $V^\theta(s)$</h2><ul>
<li><strong>Monte-Carlo(MC)</strong> based approach<br>直接使用actor的cumulated reward $G_a$作为训练资料去训练value function。这种方法需要整个流程结束才能得到训练资料。<br>MC的variance很大，因为$G_a$是有随机性的，所以每次得到的$G_a$的差别就会很大</li>
<li><strong>Temporal-difference(TD)</strong> approach<br>相较于MC，TD方法不需要走完整个流程，TD只需要$s_t,a_t,r_t,s_{t+1}$即可估测cumulated reward。<br>我们假设$\gamma=1$，由于：<script type="math/tex; mode=display">
V^\theta(s_t)=r_t+\gamma r_{t+1}+\gamma^2r_{t+2}+...</script><script type="math/tex; mode=display">
V^\theta(s_{t+1})=r_{t+1}+\gamma r_{t+2}+...</script>可得：<script type="math/tex; mode=display">
V^\theta(s_t)=\gamma V^\theta(s_{t+1})+r_t</script>那么训练value function即：使得$V^\theta(s_t)-\gamma V^\theta(s_{t+1})$和$r_t$越接近越好。<br>TD中，有随机性的是$r$，但$r$的variance比$G_a$小，因为$G_a$是很多$r$的summation。但TD中存在的问题是$V$的估测可能会不准。尽管如此，<strong>TD仍是比较常用的</strong>。</li>
</ul>
<p>[scode type=”blue”]两种方法最大的区别在于：<br>MC会假设$s_a,s_b$之间存在某种关系，即$s_a$会影响$s_b$<br>TD会假设$s_a,s_b$并不存在相互的影响[/scode]</p>
<h2 id="Version3-5"><a href="#Version3-5" class="headerlink" title="Version3.5"></a>Version3.5</h2><p>在version3中，对G进行了标准化即-b，那么b要定义为多少呢？在这个version中，$b=V^\theta(s_t)$<br><img src="images/2024/10/2644928230.png" alt="version3.5"><br>这样做的道理是：由于action是sample出来的，因此$a_t$是不确定的。$G_t^\prime$是执行了$a_t$后的cumulated reward，依照上面的计算，如果$A_t&gt;0$，那么说明$a_t$比cumulated reward的期望值要大，说明这是一个好的动作；反之则是一个坏的动作。<br>但是这里有一个问题：$G_t^\prime$是一个sample，而$V^\theta(s_t)$是一个平均，用sample去减掉平均可能并不是很合理。</p>
<h2 id="Version4"><a href="#Version4" class="headerlink" title="Version4"></a>Version4</h2><p>让上述的不合理变为合理，即用平均减去平均：<br><img src="images/2024/10/2957617261.png" alt="version4"><br>这是一个常用的方法：Advantage Actor-Critic</p>
<h2 id="Tip-of-Actor-Critic"><a href="#Tip-of-Actor-Critic" class="headerlink" title="Tip of Actor-Critic"></a>Tip of Actor-Critic</h2><p>actor是一个network，input是observation；critic是一个network，input也是observation，既然如此，我们就能让他们<strong>共享部分parameters</strong>。<br><img src="images/2024/10/3866885262.png" alt=""></p>
<h1 id="Reward-Shaping"><a href="#Reward-Shaping" class="headerlink" title="Reward Shaping"></a>Reward Shaping</h1><p>假设reward在绝大多数情况下都是0，只有在某种情况下才会得到一个reward（例如：下围棋），那么上述方法就会出现问题：不论采取怎样的action，得到的reward都差不多。<br>拿VizDoom（一款fps游戏）举例，<a target="_blank" rel="noopener" href="https://openreview.net/forum?id=Hk3mPK5gg&amp;noteId=Hk3mPK5gg">《Training Agent for First-Person Shooter Game with Actor-Critic Curriculum Learning》</a>进行了如下的reward shaping：<br><img src="images/2024/10/2143147530.png" alt=""><br>一个知名的做法是：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.05363">《Curiosity-driven Exploration by Self-supervised Prediction》</a>。简单来说就是：actor看到<strong>有意义的新鲜的东西</strong>会有reward。</p>
<h1 id="No-Reward-Learning-From-Demonstration"><a href="#No-Reward-Learning-From-Demonstration" class="headerlink" title="No Reward:Learning From Demonstration"></a>No Reward:Learning From Demonstration</h1><p>在很多情况下，很难定义reward是什么。人为定义reward带有很强的主观性，容易出问题——引起actor很奇怪的action。</p>
<h2 id="Imitation-Learning"><a href="#Imitation-Learning" class="headerlink" title="Imitation Learning"></a>Imitation Learning</h2><p>在没有reward情况下，可以提供一些expert的示范（每个示范是一个trajectory）用于actor学习。<br>这听起来很像supervised learning，就像机器只要复制人类的行为。但有些情况人类提供的示范并没有出现过，或者有些行为不该模仿而有些行为应该模仿，完全复制人类行为就会出现问题。<br>解决方法为：<strong>Inverse RL</strong>。基本思想为：本来不知道reward function，但可以通过expert的示范学到reward function。<br><img src="images/2024/10/3865662053.png" alt="Inverse RL"><br>其大体结构如下：<br><img src="images/2024/10/4095645685.png" alt="IRL"><br><img src="images/2024/10/1827051017.png" alt="Framework of IRL"><br>在训练机器手臂方面效果很好。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/week12-Reinforcement-Learning.html" data-id="cm4zg7wzb0008we3keqfyacfm" data-title="[week12]Reinforcement Learning" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-week7-Self-supervised-Learning-in-NLP" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/week7-Self-supervised-Learning-in-NLP.html" class="article-date">
  <time class="dt-published" datetime="2024-08-20T07:50:00.000Z" itemprop="datePublished">2024-08-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NTU-ML2022/">NTU-ML2022</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/week7-Self-supervised-Learning-in-NLP.html">[week7]Self-supervised Learning in NLP</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>相较于supervised learning给出成对的data和label，以及unsupervised learning全部给出无label的data，self-supervised learning更像是两者结合的产物，但由于其没有label，因此也可以算作是一种unsupervised learning。其最早出现于Yann LeCun的facebook：<br><img src="images/2024/08/1181292986.png" alt="self-supervised learning"></p>
<p>首先需要介绍一下芝麻街，这是一部动画片，self-supervised learning中一部分的Model是以其中人物命名的，包括BERT：<br><img src="images/2024/08/8646709.png" alt="Sesame Street"></p>
<h1 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h1><p>首先介绍一下BERT。原始paper：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》</a>。它其实就是一个transformer的Encoder，要做的事情就是输入一排vector，输出一排vector。BERT是一个有340M parameters的巨大模型：<br><img src="images/2024/08/3717054905.png" alt="BERT"><br>他的input是Masking Input，简单来说有两种做法：</p>
<ul>
<li>用一个special token随即盖住一些token；</li>
<li>用一些随机的token随即替换一些token。</li>
</ul>
<p>BERT要做的就是<strong>预测这些Masking的token</strong>。盖住部分对应的output经过了linear和softmax后得到一个distribution，训练的目标是<strong>output和原始Masking的部分越接近越好</strong>。</p>
<p>在大多情况下，BERT只是作为一个<strong>Pre-train的Model</strong>，要在上面进行<strong>Fine-tune</strong>（微调），做更多的Downstream Tasks。因为实际上BERT训练的就是一个做“<strong>填空题</strong>”的Model，但进行了fine-tune后可以做更多事。<br><img src="images/2024/08/1865001741.png" alt="Downstream Tasks"></p>
<p>例如，我们可以用BERT判断两个句子是不是连在一起的。我们需要将两个句子拼起来，中间加一个<strong>SEP token</strong>表示分隔，最开始加一个<strong>CLS token</strong>用于生成答案。<br><img src="images/2024/08/1667801115.png" alt="Next Sentence Prediction"></p>
<p>对于BERT的评判，由于其更像是一个“胚胎干细胞”，他的作用就是产生各种各样的Model用作不同的downstream tasks，因此对其的评判需要多种多样。GLUE（General Language Understanding Evaluation）就是一个较官方的<strong>评判集</strong>，有多个任务可以判断Language Model的好坏。<br><img src="images/2024/08/2377603511.png" alt="The General Language Understanding Evaluation (GLUE)"><br>下图是一些类似BERT的Model的GLUE score的对比图：<br><img src="images/2024/08/1636239827.png" alt="BERT and its family"><br>来源：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.00537">《SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems》</a></p>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><p>下面是一些BERT应用的举例</p>
<h3 id="Sentiment-analysis"><a href="#Sentiment-analysis" class="headerlink" title="Sentiment analysis"></a>Sentiment analysis</h3><p>输入一个seq，输出一个class。例如Sentiment analysis。<br><img src="images/2024/08/467884839.png" alt=""><br>我们需要在CLS的output上加一些额外的东西，作为我们的fine-tune。这样一个大的Model是我们要去train的，但其中BERT的部分是pre-train的，额外加的部分是随即初始化的。</p>
<p>[scode type=”yellow”]<strong>为什么要Pre-train</strong><br><img src="images/2024/08/2150153133.png" alt="《Visualizing and Understanding the Effectiveness of BERT》"><br>不难看出，<strong>pre-train</strong>的Model效果明显要好于随机初始化BERT的。[/scode]</p>
<h3 id="POS-tagging"><a href="#POS-tagging" class="headerlink" title="POS tagging"></a>POS tagging</h3><p>输入一个seq，输出相同数量class，例如POS tagging。<br><img src="images/2024/08/1912658737.png" alt=""></p>
<h3 id="Natural-Language-Inference-NLI"><a href="#Natural-Language-Inference-NLI" class="headerlink" title="Natural Language Inference(NLI)"></a>Natural Language Inference(NLI)</h3><p>输入两个seq，输出一个class。例如NLI。以下是一个例子，输入一个句子作为前提，一个句子作为假设，判断两个句子是否矛盾。<br><img src="images/2024/08/3433405695.png" alt=""><br><img src="images/2024/08/1877988107.png" alt=""></p>
<h3 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h3><p>我们还可以输入一篇文章，再输入一个问题，最后输出问题的答案。<br><img src="images/2024/08/3639479524.png" alt=""><br><img src="images/2024/08/2976768404.png" alt=""><br>但这个做法有些局限性，回答是出自文章的原句，不会自己产生其他的回答。</p>
<h2 id="other-knowledge"><a href="#other-knowledge" class="headerlink" title="other knowledge"></a>other knowledge</h2><ul>
<li>BERT实际上是很难训练的，因为其Model非常大。这篇paper讲了BERT训练的过程，探究了在训练过程中<strong>BERT究竟学到了什么</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.02480">《Pretrained Language Model Embryology: The Birth of ALBERT》</a></li>
<li>BERT实际上是pre-train了一个transformer的Encoder，我们也可以pre-train Encoder和Decoder，也就是一个会做填空题的seq2seq的Model。<br><img src="images/2024/08/3793866444.png" alt="Pre-train a seq2seq Model"><br>实际上，对于pre-train seq2seq，masking的方法有很多。这篇paper介绍了多种MASS的方法：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.02450">《MASS: Masked Sequence to Sequence Pre-training for Language Generation》</a>，这篇paper使用了上述方法pre-train了一个seq2seq：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.13461">《BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension》</a></li>
<li>惊人的发现，用一种语言fine-tune BERT，然后用另一种语言去test，居然也能在一定程度上起效果：<br><img src="images/2024/08/3314264047.png" alt=""><br>来源：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.09587">《Zero-shot Reading Comprehension by Cross-lingual Transfer Learning with Multi-lingual Language Representation Model》</a><h2 id="Why-does-BERT-work"><a href="#Why-does-BERT-work" class="headerlink" title="Why does BERT work?"></a>Why does BERT work?</h2>在BERT中，每一个token都被处理为了一个vector，这个vector叫做embedding，代表了这个token的意思。相近意思的token，其embedding也更加接近：<br><img src="images/2024/08/2030470944.png" alt="embedding"><br>可以看到，同一个token在不同的语境下，其embedding也不相同。这种考虑了语境（即上下文）的embedding叫做contextualized word embedding。一种可能的解释为，<strong>BERT在训练的过程中学到了token的意思</strong>，但一篇paper中用BERT做了蛋白质的分类，也起到了很好的效果，因此BERT在train中做的事情可能不止于此：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.07162">《Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models’ Transferability》</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/week7-Self-supervised-Learning-in-NLP.html" data-id="cm4zg7wze000lwe3k8ltkczkb" data-title="[week7]Self-supervised Learning in NLP" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-week6-Generation" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/week6-Generation.html" class="article-date">
  <time class="dt-published" datetime="2024-08-13T15:31:00.000Z" itemprop="datePublished">2024-08-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NTU-ML2022/">NTU-ML2022</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/week6-Generation.html">[week6]Generation</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Generative的Model需要input一个x，同时再从<strong>某个distribution中sample一个z</strong>，将其一同送入Model，最终产生output。<br>由于sample出的z不同，导致相同的input可能会产生不同的output，这就是Generation一个最大的特点——机器具有<strong>创造力</strong>。<br><img src="images/2024/08/3191407772.png" alt="Generation"><br>比如AI绘画，给定一些特征，每次产生的图片都不相同，这就是Generation的作用。</p>
<h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><p>在Generative Model中，其中一个知名的是<strong>Generative Adversarial Network</strong>（GAN）。有各种各样GAN的变形会在前面加上其他英文字母，例如BGAN、CGAN、SGAN…</p>
<h2 id="Unconditional-generation"><a href="#Unconditional-generation" class="headerlink" title="Unconditional generation"></a>Unconditional generation</h2><p>unconditional generation就是直接用一个Distribution sample出来的z作为input产生output，例如动漫头像生成器。<br>GAN可以分为generator和discriminator。<br>Generator输入的z是一般是一个Low-dim vector（通常50、100dim这种的），而output是一个high-dim vector，例如一张图片，其dimention可以是3×256×256。<br>Discriminator本质上就是一个neural network，它接收Generator输出的东西，输出一个数字，其值代表<strong>Generator生成结果的好坏</strong>。</p>
<p>以动漫头像生成举例，Generator接收一个随机sample的vector，然后产生一张图片，Discriminator接收这个图片，然后产生一个值，用来判断这张图片是不是生成的。</p>
<p>Generator和Discriminator的关系像是自然界中的<strong>捕食者和被捕食者</strong>，Generator试图去迷惑Discriminator，而Discriminator试图去拆穿Generator产生的东西，<strong>两者在不断的进化（训练）中共同进步</strong>，这就是Adversarial的由来。<br><img src="images/2024/08/1227872357.png" alt="Generator and Discriminator"></p>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p>首先初始化二者的parameters，在之后的每次迭代中：<br><strong>step 1</strong>：<br>固定Generator的parameters，然后用真正的东西（即train data）和Generator产生的东西去训练Discriminator，让其能有效拆穿Generator；<br><strong>step 2</strong>：<br>固定Discriminator的parameters，然后训练Generator让他努力去欺骗Discriminator。具体欺骗方法为：让Generator产生一个结果，放入Discriminator，训练Generator使其产生的结果在Discriminator中获得高分（更像真实的而非生成的）<br>如果将二者视作一个大的network：<br><img src="images/2024/08/365059681.png" alt="Large Network"></p>
<hr>
<p>训练GAN的步骤和训练其他network的步骤是没有什么差异的，同样都是使用Loss，然后Gradient Descend之类的Optimization。<br><img src="images/2024/08/2561409770.png" alt="GAN"><br>一个生成动漫头像非常好的Model：<a target="_blank" rel="noopener" href="https://gwern.net/face">《Making Anime Faces With StyleGAN》</a></p>
<h2 id="Theory-behind-GAN"><a href="#Theory-behind-GAN" class="headerlink" title="Theory behind GAN"></a>Theory behind GAN</h2><p>实际上我们要做的是：<strong>使GAN生成的output的distribution和实际事物（即train data）的distribution尽可能接近</strong>。<br><img src="images/2024/08/1496421553.png" alt="Gan&#39;s Objective"><br>那么如何衡量两个Distribution的相似度？<strong>使用divergence</strong>。divergence越小表示两个distribution越接近。因此我们的目的可以表示为：</p>
<script type="math/tex; mode=display">
G^*=\mathop{\arg\min}\limits_GDiv(P_G,P_{data})</script><p>但真正的问题是<strong>如何计算divergence</strong>，使用一些常见的divergence用于GAN，其计算过于复杂无法实现。</p>
<p>在GAN中使用了一种做法，<strong>只要知道如何从$P_G$和$P_{data}$sample出东西来，而不需要知道其具体的formulation，就能计算divergence</strong>。<br>如何smaple？从train data中直接sample就可以得到$P_{data}$，从Generator的结果中sample出一些vector，即可得到$P_G$。<br>总结一句话就是说，<strong>我们不需要知道$P_G$和$P_{data}$具体的formulation，只需要sample一些东西就能计算divergence</strong>。</p>
<p>这需要依靠Discriminator。我们要训练一个Discriminator，使其<strong>看到real data就给出一个较高的分数，而看到一个Generative data就给出一个较低的分数</strong>。因此我们要得到：</p>
<script type="math/tex; mode=display">
D^*=\mathop{\arg\max}\limits_DV(D,G)</script><p>其中$V(D,G)$就是Discriminator的Objective Function：</p>
<script type="math/tex; mode=display">
V(D,G)=E_{y\sim p_{data}}[logD(y)]+E_{y\sim p_{G}}[log(1-D(y))]</script><p>意思就是如果有一些y是从real data里产生的，那么就取$logD(y)$；如果有一些y是从generative data里产生的，那么就取$1-logD(y)$。<br>这样做的理由也很明显，<strong>要想maximum V，那么一个data如果是real的，那么通过Discriminator得到的分数越大越好，如果是generative的，那么分数就越小越好</strong>。<br>[scode type=”share”]minimize的function叫<strong>Loss function</strong><br>maximum的function叫<strong>objective function</strong>[/scode]<br>[scode type=”blue”]为什么要这样定义objective function呢？<br>这个objective就是负的cross-entropy。其实Discriminator的工作像是一个classifier，将real当作class 1，将generative当作class 2，由于classifier的loss function是cross entropy，为了将Discriminator和classifier挂上钩，因此就定义为了负的cross entropy[/scode]<br>然而，人们发现<strong>maximum objective value和JS Divergence是有关的</strong>。推导过程：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.2661">《Generative Adversarial Networks》</a>。虽然不知道怎么算Divergence，但是我们可以算objective function来间接去优化Divergence。<br>[scode type=”blue”]<strong>一种直观的理解</strong>：假如$P_G$和$P_{data}$很像，那么divergence就会很小，那么就说明很难区分，此时classifier的表现就不那么好，因此会得到一个很大的cross-entorpy，就会有一个很小$\mathop{\arg\max}\limits_DV(D,G)$。反之同理。[/scode]<br>原目标为$G^*=\mathop{\arg\min}\limits_GDiv(P_G,P_{data})$因此我们就可以用$\mathop{\arg\max}\limits_DV(D,G)$去替换divergence了：</p>
<script type="math/tex; mode=display">
G^*=\mathop{\arg}\mathop{\min}\limits_G\mathop{\max}\limits_DV(D,G)</script><p>甚至可以设计不同的objective function去估计不同的divergence：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.00709">《f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization》</a></p>
<hr>
<p>即便这样，GAN仍旧很难train——<strong>No pain,no GAN.</strong></p>
<h2 id="Tips-for-GAN——WGAN"><a href="#Tips-for-GAN——WGAN" class="headerlink" title="Tips for GAN——WGAN"></a>Tips for GAN——WGAN</h2><p>使用JS divergence会遇到这样一个问题：假设要生成一张3x256x256的动漫头像，那么有3x256x256个feature，这是一个很高维度的distribution，而真正的动漫头像$P_{data}$<strong>可能只是这个高维空间中的一个低维manifold</strong>，好比二维平面中的一条线，generative的结果$P_{G}$也是这样的一个manifold。这就会导致<strong>两个distribution的overlap的部分基本能忽略为0</strong></p>
<p><div align="center">
<img src="images/2024/08/2850269967.png" width="50%">
</div><br>或者说，尽管实际上这两个distribution确实有重叠的部分，但是sample的不够好的话，还是会导致估测这两个distribution没有overlap。</p>
<p><div align="center">
<img src="images/2024/08/1114826254.png" width="50%">
</div><br><strong>两个distribution如果没有overlap的话，那么它们的JS divergence恒为log2</strong>。因此，就算两个distribution要比另一对更加接近，使用JS divergence得到的都是一样的结果，因为<strong>这两个distribution基本不会overlap</strong>。这也就是说，model不知道怎样train，就算distribution更加接近了，model也不知道。<strong>使用binary classifier的话，正确率很容易达到100%</strong>，那么loss提供不了任何信息，根本不知道model有没有越来越好。</p>
<p>我们可以使用<strong>Wasserstein Distance</strong>代替JS divergence。<br>想象两个distribution时两堆土，有一个推土机要将一堆土推到另一堆，移动其中一个distribution的平均距离就Wasserstein Distance。<strong>应用Wasserstein Distance的GAN叫做WGAN</strong>。<br><img src="images/2024/08/3743297587.png" alt="Wasserstein Distance"><br>如果是更复杂的distribution，那么搬运的方式会有很多。用<strong>最小的搬运平均距离</strong>来定义Wasserstein Distance。<br><img src="images/2024/08/265942251.png" alt="Wasserstein Distance"><br>这样一来看起来会比较复杂，因为还需要optimization一个搬运距离。<br>我们假设能够计算，那么此时两个distribution越来越接近的时候（虽然没有overlap），但是仍能看出区别，能说明model有在变好。<br>那么如何计算？解下面的maximum function就可以得到。<br><img src="images/2024/08/1818155286.png" alt="how to compute Wasserstein Distance"><br>它的条件简单来说就是<strong>D需要足够平滑</strong>。如果不加以限制的话，那么D会给real data无限大的正值，给generative data无限大的负值。足够平滑可以避免出现这种情况：<br><img src="images/2024/08/3868237538.png" alt=""><br>最初的WGAN做法是<strong>将parameter限制在一个范围内</strong>。但这种做法效果不太好，后面提出了改进版，使用Gradient Penalty：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.00028">《Improved Training of Wasserstein GANs》</a>，还有更加改进的版本：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05957">《Spectral Normalization for Generative Adversarial Networks》</a>，叫做<strong>SNGAN</strong>，这个效果较好。</p>
<p>但GAN还面临很多问题……例如，如果Generator和Discriminator其中一者不再进步，那么整个model都会停止。<br><img src="images/2024/08/3216989683.png" alt="challenge"><br>一些其他的技巧：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/soumith/ganhacks">Tips from Soumith</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.06434">《Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.03498">《Improved Techniques for Training GANs》</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.11096">《Large Scale GAN Training for High Fidelity Natural Image Synthesis》</a></li>
</ul>
<h2 id="Conditional-Generation"><a href="#Conditional-Generation" class="headerlink" title="Conditional Generation"></a>Conditional Generation</h2><p>上文提到的generator的input只是一个随机sample的vector，现在我们额外给出一个初始的$x$一起输入，产生output。一个很具体的应用就是根据文字说明生成图片，虽然输入了相同的描述，但是由于随机sample的不同，产生的图片也不同。</p>
<p>如果用完全相同的架构去做Conditional Generation，只是加了一个input，会有一个问题：Discriminator无法判断Generator的output是否和$x$是有关的。因此，我们需要<strong>额外设计一个模块需要判断Generator的outpuut是否和$x$匹配</strong>。要训练这个模块，我们需要<strong>真实资料和标签配对的训练资料</strong>，还需要一些<strong>真实资料和标签不配对的训练资料</strong>，用来告诉Generator这是错误的。<br>一篇Conditional GAN的paper：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1605.05396">《Generative Adversarial Text to Image Synthesis》</a><br>图片转换的paper：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.07004">《Image-to-Image Translation with Conditional Adversarial Networks》</a>。paper有写到：GAN+supervised效果最好。<br>甚至可以语音转图片：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1808.04108">《Towards Audio to Scene Image Synthesis using Generative Adversarial Network》</a><br>让机器产生动图：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.08233">《Few-Shot Adversarial Learning of Realistic Neural Talking Head Models》</a></p>
<h2 id="use-GAN-in-unsupervised-learning——Cycle-GAN"><a href="#use-GAN-in-unsupervised-learning——Cycle-GAN" class="headerlink" title="use GAN in unsupervised-learning——Cycle GAN"></a>use GAN in unsupervised-learning——Cycle GAN</h2><p>如果完全没有成对匹配的资料（例如影像风格转换，真人转二次元），那么如何使用GAN学习呢？<br>完全套用前面写到的架构，Generator产生的图片可能和input没有关系。不管你输入什么，产生的就是一个随机的二次元人物，但和输入的真人没有什么特别的关系。<br>解决方法为：假设真人图片属于$x domain$，二次元图片输入$y domain$我们设置<strong>两个Generator</strong>，第一个Generator会将$x domain$转化为$y domain$，第二个Generator会将$y domain$转化为$x domain$，只要比较input的$x domain$的vector和最后产生的$x domain$的vector，其越接近越好。这组成了一个循环，因此叫Cycle GAN。<br><img src="images/2024/08/1407199455.png" alt="Cycle GAN"><br>这样做能够使得input和generative的结果<strong>有一定的关系</strong>。但我们无法保证这个关系是我们想要的（比如眼镜会变成一个痣），实际操作的时候，<strong>机器是非常懒惰的</strong>，它大概率不会去做一些奇怪的转换，也就是说，它更倾向于不去改变眼镜的样子，眼镜还是眼镜，所以这个问题不需要太担心。<br>一些其他的类似的GAN：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.05192">《Learning to Discover Cross-Domain Relations with Generative Adversarial Networks》</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1704.02510">《DualGAN: Unsupervised Dual Learning for Image-to-Image Translation》</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.10593">《Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks》</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.09020">《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1907.10830">《U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation》</a>，其网站<a target="_blank" rel="noopener" href="https://selfie2anime.com/">selfie2anime</a><br>另外，还可以做文字转换（例如将坏话转换成好话）<br><img src="images/2024/08/2856423426.png" alt="some example"><h2 id="Evaluation-of-Generation"><a href="#Evaluation-of-Generation" class="headerlink" title="Evaluation of Generation"></a>Evaluation of Generation</h2>仅凭人的直觉来判断结果的好坏显然是不合理的。一种方法是：设置一个影像分类系统，输入GAN产生的图片，然后输出一个概率分布，这个概率分布<strong>越集中越好</strong>。直观理解就是，影响辨识系统很确定这张图片是什么，说明结果很好。<br><img src="images/2024/08/1093908052.png" alt=""></li>
</ul>
<p>但用这种方法，会遇到<strong>Model collapse</strong>的问题。简单来说，就是机器只学习到<strong>产生一种类似的图片</strong>，即大部分图片都是相似的。<br><img src="images/2024/08/163771772.png" alt="Model Collapse"><br>还有一个问题：<strong>Model Dropping</strong>。这种问题表现为：多样性足够，但只学习到了train data中的一部分内容。这个问题很难被侦测到。<br><img src="images/2024/08/1652356998.png" alt="Model Dropping"><br>那么还有一种方法，在一定程度上可以解决上述问题，判断结果的好坏。将<strong>一批图片放到分类器中，得到每个图片的distribution，然后将所有distribution平均</strong>。如果结果很集中，代表多样性差；如果结果分布很平均，代表多样性好。可以用<strong>Inception Score(IS)</strong>表示结果的好坏。<br><img src="images/2024/08/2974453781.png" alt="Inception Score"><br>但IS不适用于人脸图片生成，因为即使发色、眼睛不同，但终归都是人脸，因此可能IS判断的多样性也较小。我们可以使用Fréchet Inception Distance (FID)。<br>我们取出output layer的softmax前的一层输出vector，按理说是一个distribution，然后计算其和train data的distribution的距离，距离越小越好。<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.08500">《GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium》</a><br>但有些时候，Generator可能只是将train data sample一些出来，或者将train data翻转一下，就又出现了一个问题。这说明，GAN遇到的问题还是非常多的。下面这篇paper介绍了多种评估GAN的方法：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.01844">《A note on the evaluation of generative models<br>》</a><br>一篇介绍了不同GAN效果对比的paper：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.10337">《Are GANs Created Equal? A Large-Scale Study》</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/week6-Generation.html" data-id="cm4zg7wzf000wwe3kfmui64x7" data-title="[week6]Generation" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-week5-extra-Batch-Normalization" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/week5-extra-Batch-Normalization.html" class="article-date">
  <time class="dt-published" datetime="2024-08-07T11:17:00.000Z" itemprop="datePublished">2024-08-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NTU-ML2022/">NTU-ML2022</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/week5-extra-Batch-Normalization.html">[week5 extra]Batch Normalization</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.11604">《How Does Batch Normalization Help Optimization?》</a></p>
<h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>如果某个Error surface很崎岖不平，那么对train会造成很大的困难。使用Batch Normalization可以“铲平”error surface。<br>使用batch normalization可以让各个input统一到一个范围，这样可以使得error surface变得更加“平衡”，这对train有很大的帮助。<br><img src="images/2024/08/3985165684.png" alt="change error surface"><br>具体方法为：对于某一batch的data的第$i$个dimension的feature，计算其mean $m_i$以及standard deviation $\sigma_i$，然后对于该dimension的所有feature $x_i^r$：</p>
<script type="math/tex; mode=display">
\widetilde{x}_i^r=\frac{x_i^r-m_i}{\sigma_i}</script><p>进行完这一步后，该dimension上的数值均值为0，variance为1，即<strong>其分布都在0上下</strong>。对所有dimension进行normalization后，可以“制造”一个较好的error surface，能让train更快的收敛。<br><img src="images/2024/08/1411924595.png" alt="Batch Normalization"><br>对于deep learning在经过一层neural network后，其feature的范围会发生变化，此时就需要再次进行normalization。<br>[scode type=”green”]其下一步可能要经过一层activate function，在activate function之前或之后做normalization都是可以的。[/scode]<br><img src="images/2024/08/583778970.png" alt=""><br>在这种操作中，$\mu$和$\sigma$是由所有的$z$计算得到的，因此改变其中某个$z^i$，都会对其产生影响，进而会对所有$\widetilde{z}$产生影响。总结而言，在不进行Batch normalization的时候，<strong>每个example是独立计算、互不影响的</strong>，但进行了Batch Normalization后，<strong>某个example的会影响其他example</strong>，因为$\mu$和$\sigma$是共享的。相当于<strong>合并为了一个更大的network</strong>。<br>[scode type=”yellow”]使用Batch Normalization的时候，<strong>batch size</strong>一定要大。这样计算出来的$\mu$和$\sigma$才能更好的代表所有data。[/scode]</p>
<p>做完batch normalization后，还需要对每个$\widetilde{z}$<strong>乘以一个数，加上一个数</strong>，这个parameter是通过学习得到的。这样做后，可以使得$\widetilde{z}$的均值不为0。<br><img src="images/2024/08/149684587.png" alt=""><br>[scode type=”yellow”]均值为0可能对训练产生影响[/scode]<br>[scode type=”green”]如果进行了这一步操作，那不就白做Batch Normalization了吗？<br>初始的时候，$\gamma$为1，$\beta$为0，因此初期并不会“白做”。到了训练后期，找到了一个较好的error surface后，$\gamma$和$\beta$才会显著增加。[/scode]</p>
<hr>
<h1 id="Batch-Normalization-for-Testing-Inference"><a href="#Batch-Normalization-for-Testing-Inference" class="headerlink" title="Batch Normalization for Testing(Inference)"></a>Batch Normalization for Testing(Inference)</h1><p>test的时候，如果没有batch，那么解决方法是<strong>在training的时候计算moving average</strong>：<br>假设training的时候经历了$batch^1,batch^2,…,batch^t$，其均值分别为$\mu^1,\mu^2,…,\mu^t$那么计算完$batch^t$后，得到$\mu$的moving average为：</p>
<script type="math/tex; mode=display">
\bar{\mu}=p\bar{\mu}+(1-p)\mu^t</script><p>其中$p$为hyperparameter，在pytorch中默认为0.1。<br>同样，$\sigma$也是同样处理。使用$\bar{\mu}$和$\bar{\sigma}$去处理test data即可。</p>
<h1 id="To-Learn-More"><a href="#To-Learn-More" class="headerlink" title="To Learn More"></a>To Learn More</h1><p>还有一些比较知名的normalization的方法：<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1702.03275">Batch Renormalization</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1607.08022">Instance Normalization</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1803.08494">Group Normalization</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1602.07868">Weight Normalization</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.10941">Spectrum Normalization</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/week5-extra-Batch-Normalization.html" data-id="cm4zg7wze000jwe3kc8phfzx4" data-title="[week5 extra]Batch Normalization" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-HW-3-CNN" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/HW-3-CNN.html" class="article-date">
  <time class="dt-published" datetime="2024-08-07T08:59:00.000Z" itemprop="datePublished">2024-08-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NTU-ML2022/">NTU-ML2022</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/HW-3-CNN.html">[HW 3]CNN</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numeric operation</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># data i\o</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># garbage collect</span></span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"></span><br><span class="line"><span class="comment"># progress bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># PyTorch</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensorboard</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># run time</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># image operation</span></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;necessary function&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">same_seed</span>(<span class="params">seed</span>):</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed_all(seed)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    transforms.RandomResizedCrop((<span class="number">128</span>, <span class="number">128</span>), (<span class="number">0.7</span>, <span class="number">1.0</span>)),</span><br><span class="line">    transforms.RandomHorizontalFlip(<span class="number">0.5</span>),</span><br><span class="line">    transforms.RandomVerticalFlip(<span class="number">0.5</span>),</span><br><span class="line">    transforms.RandomRotation(<span class="number">180</span>),</span><br><span class="line">    transforms.RandomAffine(<span class="number">20</span>),</span><br><span class="line">    transforms.RandomGrayscale(<span class="number">0.3</span>),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;hyperparameters&quot;&quot;&quot;</span></span><br><span class="line">device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&#x27;seed&#x27;</span>: <span class="number">5201314</span>,</span><br><span class="line">    <span class="string">&#x27;k_fold&#x27;</span>: <span class="number">4</span>,</span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: <span class="number">64</span>,</span><br><span class="line">    <span class="string">&#x27;lr&#x27;</span>: <span class="number">4e-4</span>,</span><br><span class="line">    <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">2e-5</span>,</span><br><span class="line">    <span class="string">&#x27;epochs&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">&#x27;early_stop&#x27;</span>: <span class="number">30</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;dataset&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Hw3Dataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path=<span class="literal">None</span>, tfm=test_tfm, files=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Hw3Dataset, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.path = path</span><br><span class="line">        <span class="keyword">if</span> files <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>.files = <span class="built_in">sorted</span>([os.path.join(path, x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(path) <span class="keyword">if</span> x.endswith(<span class="string">&#x27;.jpg&#x27;</span>)])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.files = files</span><br><span class="line">        <span class="variable language_">self</span>.transform = tfm</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.files)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        fname = <span class="variable language_">self</span>.files[idx]</span><br><span class="line">        im = Image.<span class="built_in">open</span>(fname)</span><br><span class="line">        im = <span class="variable language_">self</span>.transform(im)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            label = <span class="built_in">int</span>(fname.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;_&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            label = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> im, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;pretreatment data&quot;&quot;&quot;</span></span><br><span class="line">same_seed(config[<span class="string">&#x27;seed&#x27;</span>])</span><br><span class="line"></span><br><span class="line">root = <span class="string">&#x27;./food11&#x27;</span></span><br><span class="line">train_files = [os.path.join(root, <span class="string">&#x27;training&#x27;</span>, x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(os.path.join(root, <span class="string">&#x27;training&#x27;</span>))\</span><br><span class="line">               <span class="keyword">if</span> x.endswith(<span class="string">&#x27;.jpg&#x27;</span>)]</span><br><span class="line">val_files = [os.path.join(root, <span class="string">&#x27;validation&#x27;</span>, x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(os.path.join(root, <span class="string">&#x27;validation&#x27;</span>))\</span><br><span class="line">             <span class="keyword">if</span> x.endswith(<span class="string">&#x27;.jpg&#x27;</span>)]</span><br><span class="line">total_files = train_files + val_files</span><br><span class="line">random.shuffle(total_files)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;Model&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Hw3Model</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.block = block</span><br><span class="line">        <span class="comment"># input 3 x 128 x 128</span></span><br><span class="line">        <span class="variable language_">self</span>.b1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>),  <span class="comment"># 64 x 64 x 64</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># 64 x 32 x 32</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.b2 = nn.Sequential(*<span class="variable language_">self</span>.resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>))</span><br><span class="line">        <span class="variable language_">self</span>.b3 = nn.Sequential(*<span class="variable language_">self</span>.resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">4</span>))  <span class="comment"># 128 x 16 x 16</span></span><br><span class="line">        <span class="variable language_">self</span>.b4 = nn.Sequential(*<span class="variable language_">self</span>.resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>))  <span class="comment"># 256 x 8 x 8</span></span><br><span class="line">        <span class="variable language_">self</span>.b5 = nn.Sequential(*<span class="variable language_">self</span>.resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">1</span>))  <span class="comment"># 512 x 4 x 4</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.net = nn.Sequential(</span><br><span class="line">            <span class="variable language_">self</span>.b1, <span class="variable language_">self</span>.b2, <span class="variable language_">self</span>.b3, <span class="variable language_">self</span>.b4, <span class="variable language_">self</span>.b5,  <span class="comment"># 512 x 4 x 4</span></span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.net(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">resnet_block</span>(<span class="params">self, in_channels, out_channels, num_residuals, first_block=<span class="literal">False</span></span>):</span><br><span class="line">        blk = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block:</span><br><span class="line">                blk.append(<span class="variable language_">self</span>.block(in_channels, out_channels, stride=<span class="number">2</span>, use_1x1conv=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                blk.append(<span class="variable language_">self</span>.block(out_channels, out_channels))</span><br><span class="line">        <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Residual_Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels, output_channels, stride=<span class="number">1</span>, use_1x1conv=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            <span class="variable language_">self</span>.conv3 = nn.Conv2d(input_channels, output_channels, kernel_size=<span class="number">1</span>, stride=stride)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.conv3 = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(output_channels)</span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(output_channels)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = F.relu(<span class="variable language_">self</span>.bn1(<span class="variable language_">self</span>.conv1(x)))</span><br><span class="line">        y = <span class="variable language_">self</span>.bn2(<span class="variable language_">self</span>.conv2(y))</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.conv3 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = <span class="variable language_">self</span>.conv3(x)</span><br><span class="line">        y += x</span><br><span class="line">        <span class="keyword">return</span> F.relu(y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;training loop&quot;&quot;&quot;</span></span><br><span class="line">fold_num = <span class="built_in">len</span>(total_files) // config[<span class="string">&#x27;k_fold&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;k_fold&#x27;</span>]):</span><br><span class="line">    fold = i + <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Current fold: &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(fold, config[<span class="string">&#x27;k_fold&#x27;</span>]))</span><br><span class="line">    model = Hw3Model(Residual_Block).to(device)</span><br><span class="line">    criterion = nn.CrossEntropyLoss().to(device)</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=config[<span class="string">&#x27;lr&#x27;</span>], weight_decay=config[<span class="string">&#x27;weight_decay&#x27;</span>])</span><br><span class="line">    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=<span class="number">16</span>, T_mult=<span class="number">1</span>)</span><br><span class="line">    early_stop_count = <span class="number">0</span></span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    valid_data = total_files[i * fold_num:(i + <span class="number">1</span>) * fold_num]</span><br><span class="line">    train_data = total_files[:i * fold_num] + total_files[(i + <span class="number">1</span>) * fold_num:]</span><br><span class="line"></span><br><span class="line">    train_set = Hw3Dataset(train_tfm, files=train_data)</span><br><span class="line">    train_loader = DataLoader(train_set, batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>], shuffle=<span class="literal">True</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    valid_set = Hw3Dataset(train_tfm, files=valid_data)</span><br><span class="line">    valid_loader = DataLoader(valid_set, batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>], shuffle=<span class="literal">True</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    n_epochs = config[<span class="string">&#x27;epochs&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        train_loss, train_acc, valid_loss, valid_acc = [], [], [], []</span><br><span class="line">        train_bar = tqdm(train_loader, position=<span class="number">0</span>, leave=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> image, label <span class="keyword">in</span> train_bar:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            image, label = image.to(device), label.to(device)</span><br><span class="line">            logits = model(image)</span><br><span class="line">            loss = criterion(logits, label)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            acc = (logits.argmax(dim=-<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">            train_loss.append(loss.item())</span><br><span class="line">            train_acc.append(acc)</span><br><span class="line"></span><br><span class="line">            scheduler.step()</span><br><span class="line"></span><br><span class="line">        train_bar.set_description(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_epochs&#125;</span>]&#x27;</span>)</span><br><span class="line">        train_bar.set_postfix(&#123;<span class="string">&#x27;train loss&#x27;</span>: <span class="built_in">sum</span>(train_loss) / <span class="built_in">len</span>(train_loss)&#125;)</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        valid_bar = tqdm(valid_loader, position=<span class="number">0</span>, leave=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> image, label <span class="keyword">in</span> valid_bar:</span><br><span class="line">            image, label = image.to(device), label.to(device)</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                logits = model(image)</span><br><span class="line">                loss = criterion(logits, label)</span><br><span class="line">                acc = (logits.argmax(dim=-<span class="number">1</span>) == label).<span class="built_in">float</span>().mean()</span><br><span class="line">            valid_loss.append(loss.item())</span><br><span class="line">            valid_acc.append(acc)</span><br><span class="line"></span><br><span class="line">        train_bar.set_description(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_epochs&#125;</span>]&#x27;</span>)</span><br><span class="line">        train_bar.set_postfix(&#123;<span class="string">&#x27;valid loss&#x27;</span>: <span class="built_in">sum</span>(valid_loss) / <span class="built_in">len</span>(valid_loss)&#125;)</span><br><span class="line">        valid_acc = <span class="built_in">sum</span>(valid_acc) / <span class="built_in">len</span>(valid_acc)</span><br><span class="line"></span><br><span class="line">        train_acc = <span class="built_in">sum</span>(train_acc) / <span class="built_in">len</span>(train_acc)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_epochs&#125;</span>]: train acc: <span class="subst">&#123;train_acc&#125;</span>, valid_acc: <span class="subst">&#123;valid_acc&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> valid_acc &gt; best_acc:</span><br><span class="line">            best_acc = valid_acc</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;saving model with acc <span class="subst">&#123;best_acc&#125;</span> at fold <span class="subst">&#123;fold&#125;</span> epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>&#x27;</span>)</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">f&#x27;Fold_<span class="subst">&#123;fold&#125;</span>_best.pth&#x27;</span>)</span><br><span class="line">            early_stop_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            early_stop_count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> early_stop_count &gt; config[<span class="string">&#x27;early_stop&#x27;</span>]:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&#x27;\nModel is not improving, so we halt the training&#x27;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;predict&quot;&quot;&quot;</span></span><br><span class="line">test_data = [os.path.join(root, <span class="string">&#x27;test&#x27;</span>, x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(os.path.join(root, <span class="string">&#x27;test&#x27;</span>)) <span class="keyword">if</span> x.endswith(<span class="string">&#x27;.jpg&#x27;</span>)]</span><br><span class="line">test_set = Hw3Dataset(test_tfm, files=test_data)</span><br><span class="line">test_loader = DataLoader(test_set, batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>], shuffle=<span class="literal">False</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;tta&quot;&quot;&quot;</span></span><br><span class="line">tta_loader = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    tta_set_i = Hw3Dataset(train_tfm, files=test_data)</span><br><span class="line">    tta_loader_i = DataLoader(tta_set_i, batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>], shuffle=<span class="literal">False</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    tta_loader.append(tta_loader_i)</span><br><span class="line"></span><br><span class="line">models = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(config[<span class="string">&#x27;k_fold&#x27;</span>]):</span><br><span class="line">    fold = i + <span class="number">1</span></span><br><span class="line">    model_best = Hw3Model(Residual_Block).to(device)</span><br><span class="line">    model_best.load_state_dict(torch.load(<span class="string">f&#x27;Fold_<span class="subst">&#123;fold&#125;</span>_best.pth&#x27;</span>))</span><br><span class="line">    model_best.<span class="built_in">eval</span>()</span><br><span class="line">    models.append(model_best)</span><br><span class="line"></span><br><span class="line">preds = [[], [], [], [], [], []]</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> img, _ <span class="keyword">in</span> test_loader:</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        batch_preds = []</span><br><span class="line">        <span class="keyword">for</span> model <span class="keyword">in</span> models:</span><br><span class="line">            batch_preds.append(model(img).cpu().data.numpy())</span><br><span class="line">        batch_preds = <span class="built_in">sum</span>(batch_preds)</span><br><span class="line">        preds[<span class="number">0</span>].extend(batch_preds.squeeze().tolist())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, loader <span class="keyword">in</span> <span class="built_in">enumerate</span>(tta_loader):</span><br><span class="line">        <span class="keyword">for</span> data, _ <span class="keyword">in</span> loader:</span><br><span class="line">            batch_preds = []</span><br><span class="line">            <span class="keyword">for</span> model_best <span class="keyword">in</span> models:</span><br><span class="line">                batch_preds.append(model_best(data.to(device)).cpu().data.numpy())</span><br><span class="line">            batch_preds = <span class="built_in">sum</span>(batch_preds)</span><br><span class="line">            preds[i + <span class="number">1</span>].extend(batch_preds.squeeze().tolist())</span><br><span class="line"></span><br><span class="line">preds = np.array(preds)</span><br><span class="line">preds = <span class="number">0.6</span> * preds[<span class="number">0</span>] + <span class="built_in">sum</span>(<span class="number">0.1</span> * t <span class="keyword">for</span> t <span class="keyword">in</span> preds[<span class="number">1</span>:])</span><br><span class="line">prediction = np.argmax(preds, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pad4</span>(<span class="params">i</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>*(<span class="number">4</span>-<span class="built_in">len</span>(<span class="built_in">str</span>(i)))+<span class="built_in">str</span>(i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame()</span><br><span class="line">df[<span class="string">&quot;Id&quot;</span>] = [pad4(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(test_set)+<span class="number">1</span>)]</span><br><span class="line">df[<span class="string">&quot;Category&quot;</span>] = prediction</span><br><span class="line">df.to_csv(<span class="string">&quot;submission.csv&quot;</span>,index = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test_dir = <span class="string">&quot;food11/test&quot;</span></span><br><span class="line">test_set = Hw3Dataset(test_dir, tfm=test_tfm)</span><br><span class="line">test_loader = DataLoader(test_set, batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>], shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dir = <span class="string">&quot;food11/test&quot;</span></span><br><span class="line">test_loaders = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    test_set_i = Hw3Dataset(test_dir, tfm=train_tfm)</span><br><span class="line">    test_loader_i = DataLoader(test_set_i, batch_size=config[<span class="string">&#x27;batch_size&#x27;</span>], shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    test_loaders.append(test_loader_i)</span><br><span class="line"></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"></span><br><span class="line">models = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">4</span>):</span><br><span class="line">    fold = i + <span class="number">1</span></span><br><span class="line">    model_best = Hw3Model(Residual_Block).to(device)</span><br><span class="line">    model_best.load_state_dict(torch.load(<span class="string">f&quot;Fold_<span class="subst">&#123;fold&#125;</span>_best.pth&quot;</span>))</span><br><span class="line">    model_best.<span class="built_in">eval</span>()</span><br><span class="line">    models.append(model_best)</span><br><span class="line"></span><br><span class="line">preds = [[], [], [], [], [], []]</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data, _ <span class="keyword">in</span> test_loader:</span><br><span class="line">        batch_preds = []</span><br><span class="line">        <span class="keyword">for</span> model_best <span class="keyword">in</span> models:</span><br><span class="line">            batch_preds.append(model_best(data.to(device)).cpu().data.numpy())</span><br><span class="line">        batch_preds = <span class="built_in">sum</span>(batch_preds)</span><br><span class="line">        preds[<span class="number">0</span>].extend(batch_preds.squeeze().tolist())</span><br><span class="line"></span><br><span class="line">        <span class="comment">#batch_label = np.argmax(batch_preds, axis=1)</span></span><br><span class="line">        <span class="comment">#prediction += batch_label.squeeze().tolist()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, loader <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loaders):</span><br><span class="line">        <span class="keyword">for</span> data, _ <span class="keyword">in</span> loader:</span><br><span class="line">            batch_preds = []</span><br><span class="line">            <span class="keyword">for</span> model_best <span class="keyword">in</span> models:</span><br><span class="line">                batch_preds.append(model_best(data.to(device)).cpu().data.numpy())</span><br><span class="line">            batch_preds = <span class="built_in">sum</span>(batch_preds)</span><br><span class="line">            preds[i+<span class="number">1</span>].extend(batch_preds.squeeze().tolist())</span><br><span class="line"></span><br><span class="line">preds = np.array(preds)</span><br><span class="line"><span class="built_in">print</span>(preds.shape)</span><br><span class="line">preds = <span class="number">0.6</span>* preds[<span class="number">0</span>] + <span class="number">0.1</span> * preds[<span class="number">1</span>] + <span class="number">0.1</span> * preds[<span class="number">2</span>] + <span class="number">0.1</span> * preds[<span class="number">3</span>] + <span class="number">0.1</span> * preds[<span class="number">4</span>] + <span class="number">0.1</span> * preds[<span class="number">5</span>]</span><br><span class="line"><span class="built_in">print</span>(preds.shape)</span><br><span class="line">prediction = np.argmax(preds, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#create test csv</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pad4</span>(<span class="params">i</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>*(<span class="number">4</span>-<span class="built_in">len</span>(<span class="built_in">str</span>(i)))+<span class="built_in">str</span>(i)</span><br><span class="line">df = pd.DataFrame()</span><br><span class="line">df[<span class="string">&quot;Id&quot;</span>] = [pad4(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(test_set)+<span class="number">1</span>)]</span><br><span class="line">df[<span class="string">&quot;Category&quot;</span>] = prediction</span><br><span class="line">df.to_csv(<span class="string">&quot;submission.csv&quot;</span>,index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/HW-3-CNN.html" data-id="cm4zg7wz80001we3k5262843s" data-title="[HW 3]CNN" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-week4-Sequence-as-input——self-attention" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/articles/week4-Sequence-as-input%E2%80%94%E2%80%94self-attention.html" class="article-date">
  <time class="dt-published" datetime="2024-08-07T08:53:00.000Z" itemprop="datePublished">2024-08-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NTU-ML2022/">NTU-ML2022</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/articles/week4-Sequence-as-input%E2%80%94%E2%80%94self-attention.html">[week4]Sequence as input——self attention</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Sequence-as-input"><a href="#Sequence-as-input" class="headerlink" title="Sequence as input"></a>Sequence as input</h1><p>在有些背景下input是<strong>一组数量不定的vector</strong>。<br>举例来说，在<strong>语句处理</strong>领域，可以将每个word视作一个vector；在<strong>语音处理</strong>方面，可以将一段语音的一个Frame视作一个vector；或者在<strong>Graph</strong>的问题中，可以将一个node视作一个vector。</p>
<p>Sequence as input的问题主要有以下三种：</p>
<ul>
<li>每个vector<strong>都有一个label</strong>（例如POS tagging）；</li>
<li>整个sequence的output是<strong>一个label</strong>（例如sentiment analysis、speaker recognization）；</li>
<li><strong>Model决定输出vector的数量</strong>，叫做<strong>Seq2Seq</strong>（例如翻译）。</li>
</ul>
<p>本文以第一种：每个vector<strong>都有一个label</strong>（又叫<strong>Sequence labling</strong>）为例来讨论<strong>Self-attention的工作机制</strong>。</p>
<h1 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h1><p>对于一个sequence，fully-connected network有一个显著的缺陷：<strong>无法考虑多个vector之间的关联</strong>。而HW2中多个vector拼接为一个vector的方法不适用于<strong>seq长度可变</strong>的情况。self-attention就是用来处理sequence as input的情况的。</p>
<h2 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h2><p>对于seq中每一个input vector，self-attention会吃一整个seq的信息，并输output一个特特殊的vector：<br><img src="images/2024/08/3787030471.png" alt="self-attention"><br>具体是如何做到的后面会详细说明，self-attention可以叠加使用多次：self-attention处理整个seq的信息，然后使用fc处理每个单独vector的信息，再使用self-attention处理整个output vector seq的信息…</p>
<p>假设input seq中有一个vector是$a^i$，那么其输出$b^i$是综合了seq中所有vector得到的：<br><img src="images/2024/08/4000611276.png" alt="self-attention"><br>这里只解释$b^1$的形成机制，其他的同理。</p>
<h2 id="relevant"><a href="#relevant" class="headerlink" title="relevant"></a>relevant</h2><p>我们想找到所有与$a^1$相关的vector，又不想考虑与$a^1$无关的vector，因此，第一步就是<strong>计算$a^1$与其他vector的相关性</strong>。这里有一个专门处理两个vector $a^i$和$a^j$关联程度的方法，即输入$a^i$和$a^j$，输出其<strong>关联程度$\alpha_{i,j}$</strong>。具体的计算方法不一，较为常见的为<strong>使用Dot-product</strong>：令$a^i$乘以矩阵$W^q$得到$q$，$a^j$乘以矩阵$W^k$得到$k$，那么$\alpha_{i,j}=q\cdot k$，其中$\alpha$叫做<strong>attention score</strong>。还有一种常见的方法为Additive，如下图所示：<br><img src="images/2024/08/3734183805.png" alt="Dot-productive and Additive"><br>本文主要使用Dot-product，这是最常用的，也是transformer中使用的。</p>
<p>应用在self-attention中，计算$a^1$和其他所有vector的关联性，实际操作中，<strong>自己也要和自己计算关联性</strong>。计算完关联性后，所有的$\alpha$经过一个softmax后得到$\alpha^\prime$（没有什么道理，使用其他normalization也行）：<br><img src="images/2024/08/2712051742.png" alt="compute relevant"></p>
<p>得到所有的attention score后，要从中提取信息，方法为：对于$\alpha^1$，先将所有的$\alpha$乘以一个矩阵$W^v$得到$v$，然后乘以其对应的attention score，再将结果相加（即对$v$做一个<strong>weighted sum</strong>）得到$b^1$，那么<strong>谁的$v$越接近$b^1$，代表谁和$\alpha^1$越相关</strong>：<br><img src="images/2024/08/4055030727.png" alt=""><br>在这个例子中，从$a^1~a^4$得到$b^1~b^4$的过程，就是<strong>self-attention</strong>的过程。其计算过程看似复杂，但以矩阵的视角来进行，其所有计算都是同时进行的。</p>
<h2 id="self-attention-matrix-representation"><a href="#self-attention-matrix-representation" class="headerlink" title="self-attention matrix-representation"></a>self-attention matrix-representation</h2><p>所有$b^i$的得到方式与$b^1$同理，那么有：</p>
<script type="math/tex; mode=display">
q^i=W^qa^i</script><script type="math/tex; mode=display">
k^i=W^ka^i</script><script type="math/tex; mode=display">
v^i=W^va^i</script><p>将所有的$a$拼接为一个矩阵，可以得到：<br><img src="images/2024/08/3755362515.png" alt="self-attention matrix-representation"><br>接下来，每一个$q$会和每一个$k$做Dot-product，得到attention score，同样将其拼接为一个矩阵：<br><img src="images/2024/08/1149814991.png" alt="self-attention matrix-representation"><br>综合以上两步以及normalization，可以得到所有的attention score：<br><img src="images/2024/08/2304290509.png" alt="self-attention matrix-representation"><br>最后对每一个$a$的$v$做一个weighted sum，得到$b$：<br><img src="images/2024/08/3114213706.png" alt="self-attention matrix-representation"></p>
<p>总结以上所有过程，得到self-attention真正运作的过程：<br><img src="images/2024/08/1109922326.png" alt="self-attention matrix-representation"><br>看似复杂的操作，其中<strong>需要学习的parameters只有$W^q、W^k、W^v$</strong>。</p>
<h1 id="Multi-head-Self-attention"><a href="#Multi-head-Self-attention" class="headerlink" title="Multi-head Self-attention"></a>Multi-head Self-attention</h1><p>[scode type=”share”]<strong>why multi-head</strong>?<br>两个事物的相关性可能有<strong>多种表现形式</strong>，需要用不同的$q、k、v$来表示不同的相关性[/scode]<br>以two heads为例，其做法为：对于一个$a^i$的$q^i、k^i、v^i$，分别乘以两个不同的矩阵，得到两组矩阵：$q^{i,1}、k^{i,1}、v^{i,1}$和$q^{i,2}、k^{i,2}、v^{i,2}$，对两组矩阵分别进行self-attention。<br><img src="images/2024/08/1437060038.png" alt="2 heads self-attention"><br>随后将其attention score综合起来，得到最终的attention score</p>
<p><div align="center">
<img src="images/2024/08/2963752312.png" width="50%">
</div></p>
<h1 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h1><p>上面的self-attention有一个缺陷：<strong>无法考虑每个vector的位置信息</strong>。但位置的信息在某些情况下非常重要。<br>解决方法为使用<strong>Positional Encoding</strong>，即为seq中每一个vector $a$都加上一个位置信息$e$，这个e是<strong>人为设置的</strong>，所以其设置方法仍是一个可深入研究的问题。下图是一个$e$的设置方法举例：<br><img src="images/2024/08/1545176778.png" alt="Positional Encoding"><br>一篇有关Positional Encoding的paper：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.09229">Learning to Encode Position for Transformer with Continuous Dynamical Model</a></p>
<h1 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h1><p>self-attention在许多方面都有应用，例如transformer <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">《attention is all you need》</a>；BERT <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》</a></p>
<h2 id="Truncated-Self-attention"><a href="#Truncated-Self-attention" class="headerlink" title="Truncated Self-attention"></a>Truncated Self-attention</h2><p>self-attention中需要学习的$W^q、W^k、W^v$，其parameters的大小是同seq中vector的数量成平方关系的，因此seq中的vector数量很大很大的时候，parameters的数量会特别大，导致Model训练很困难。因此在某些情况下，可以<strong>只考虑seq中部分vector</strong>，此即Truncated self-attention。例如在语音辨识中，当前vector可能只和其附近的vector有关联，详见<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.12977">《Transformer-Transducer: End-to-End Speech Recognition with Self-Attention》</a>。<br><img src="images/2024/08/500544821.png" alt="Truncated self-attention"></p>
<h2 id="self-attention-for-Image"><a href="#self-attention-for-Image" class="headerlink" title="self-attention for Image"></a>self-attention for Image</h2><p>对于一张图片，可以同时将其三个channels视作一个Sequence，这也可以视作为sequence as input，因此<strong>对于一张图片，也有应用self-attention的可能性</strong>。<br><img src="images/2024/08/1543565533.png" alt="self-attention for Image"><br>下面这两个paper就在image处理中使用了self-attention：<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.08318">《Self-Attention Generative Adversarial Networks》</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.12872">《End-to-End Object Detection with Transformers》</a></p>
<h1 id="Self-attention-v-s-CNN"><a href="#Self-attention-v-s-CNN" class="headerlink" title="Self-attention v.s. CNN"></a>Self-attention v.s. CNN</h1><p>self-attention和CNN都是同时考虑多个vector，如果将一组<strong>强相关的vector</strong>视作一个receptive filed，那么相比于CNN的receptive filed，<strong>self-attention</strong>的receptive filed是Model学习得到的。<br><img src="images/2024/08/3259953941.png" alt="Self-attention v.s. CNN"><br>这篇paper使用严谨的数学推导描述了其关系：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.03584">《On the Relationship between Self-Attention and Convolutional Layers》</a></p>
<p>这篇paper中讲述了self-attention和CNN的对比：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.11929">《An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale》</a><br><img src="images/2024/08/2841154817.png" alt=""><br>结果显示，在train data较少的时候，CNN表现更好；在train data较多的时候，self-attention效果更好。可能的原因是：self-attention的Model弹性更大，需要更多的data来train。</p>
<h1 id="Self-attention-v-s-RNN"><a href="#Self-attention-v-s-RNN" class="headerlink" title="Self-attention v.s. RNN"></a>Self-attention v.s. RNN</h1><p>以下图来解释两者的关系：<br><img src="images/2024/08/2899915646.png" alt="Self-attention v.s. RNN"><br>相较于self-attention，RNN<strong>很难考虑距离较远的vector</strong>，并且RNN的无法平行计算，其效率远不如self-attention。因此，self-attention在很大程度上是优于RNN的，当前很多RNN架构也逐渐self-attention化。更详细的讲解：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.16236">《ransformers are RNNs: Fast Autoregressive Transformers with Linear Attention》</a></p>
<h1 id="Self-attention-for-Graph"><a href="#Self-attention-for-Graph" class="headerlink" title="Self-attention for Graph"></a>Self-attention for Graph</h1><p>Graph中的每个node也可以作为seq输入，因此graph也可以应用self-attention。这也是GNN的一种。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zz111y.github.io/articles/week4-Sequence-as-input%E2%80%94%E2%80%94self-attention.html" data-id="cm4zg7wzd000hwe3k9v1l2lnd" data-title="[week4]Sequence as input——self attention" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DeepLearning/">DeepLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Env-Setting/">Env Setting</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NTU-ML2022/">NTU-ML2022</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/08/">August 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/articles/linux%E9%85%8D%E7%BD%AEgit%E5%B9%B6%E9%83%A8%E7%BD%B2%E5%88%B0github.html">linux配置git并部署到github</a>
          </li>
        
          <li>
            <a href="/articles/ubuntu%E4%B8%8B%E7%94%A8qemu%E6%A8%A1%E6%8B%9Ffreedos%E7%BC%96%E5%86%9916%E4%BD%8D%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80.html">ubuntu下用qemu模拟freedos编写16位汇编语言</a>
          </li>
        
          <li>
            <a href="/articles/week12-extra-Q-learning.html">[week12 extra] Q-learning</a>
          </li>
        
          <li>
            <a href="/articles/ubuntu%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%A4%9A%E7%89%88%E6%9C%ACcuda%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%87%E6%8D%A2.html">ubuntu环境下多版本cuda的安装与切换</a>
          </li>
        
          <li>
            <a href="/articles/week12-Reinforcement-Learning.html">[week12]Reinforcement Learning</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 zz111y<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>